{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dd28474-17b0-4734-9bb8-3d80969ead66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91428312-f7f9-4345-b31d-78835eab21e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1eb20eb47d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0, 10)\n",
    "\n",
    "y = [3, 4, 5, 7, 9, 8, 9, 10, 12, 18]\n",
    "\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9c71fbe-cff5-47dc-b354-5d3ec76b9918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1eb23108d70>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree = 3)\n",
    "\n",
    "poly_features = poly.fit_transform(x.reshape(-1, 1))\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(poly_features, y)\n",
    "\n",
    "y_pred = model.predict(poly_features)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, y_pred, c = 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6ebc68-5353-4de5-996a-eb1a7d335faa",
   "metadata": {},
   "source": [
    "# Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "260cce3e-efcf-44e9-9d89-b6e947323c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x18b30b12d80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/Position_Salaries.csv')\n",
    "\n",
    "x = df.iloc[:, 1].values\n",
    "y = df.iloc[:, 2].values\n",
    "\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5857dceb-8d41-4afd-a604-8ee13c6b233e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1eb24656120>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree = 2)\n",
    "\n",
    "poly_x = poly.fit_transform(x.reshape(-1, 1))\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "model.fit(poly_x, y)\n",
    "\n",
    "y_pred = model.predict(poly_x)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, y_pred, c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1616262-8f00-4dd9-8ee2-09ebef66677d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package sklearn.preprocessing in sklearn:\n",
      "\n",
      "NAME\n",
      "    sklearn.preprocessing - Methods for scaling, centering, normalization, binarization, and more.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _csr_polynomial_expansion\n",
      "    _data\n",
      "    _discretization\n",
      "    _encoders\n",
      "    _function_transformer\n",
      "    _label\n",
      "    _polynomial\n",
      "    _target_encoder\n",
      "    _target_encoder_fast\n",
      "    tests (package)\n",
      "\n",
      "CLASSES\n",
      "    sklearn.base.BaseEstimator(sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin, sklearn.utils._metadata_requests._MetadataRequester)\n",
      "        sklearn.preprocessing._data.Binarizer(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._data.KernelCenterer(sklearn.base.ClassNamePrefixFeaturesOutMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._data.MaxAbsScaler(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._data.MinMaxScaler(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._data.Normalizer(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._data.PowerTransformer(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._data.QuantileTransformer(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._data.RobustScaler(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._data.StandardScaler(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._discretization.KBinsDiscretizer(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._function_transformer.FunctionTransformer(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._label.LabelBinarizer(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._label.LabelEncoder(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._label.MultiLabelBinarizer(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._polynomial.PolynomialFeatures(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._polynomial.SplineTransformer(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "    sklearn.base.ClassNamePrefixFeaturesOutMixin(builtins.object)\n",
      "        sklearn.preprocessing._data.KernelCenterer(sklearn.base.ClassNamePrefixFeaturesOutMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "    sklearn.base.OneToOneFeatureMixin(builtins.object)\n",
      "        sklearn.preprocessing._data.Binarizer(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._data.MaxAbsScaler(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._data.MinMaxScaler(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._data.Normalizer(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._data.PowerTransformer(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._data.QuantileTransformer(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._data.RobustScaler(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._data.StandardScaler(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._encoders.OrdinalEncoder(sklearn.base.OneToOneFeatureMixin, sklearn.preprocessing._encoders._BaseEncoder)\n",
      "        sklearn.preprocessing._target_encoder.TargetEncoder(sklearn.base.OneToOneFeatureMixin, sklearn.preprocessing._encoders._BaseEncoder)\n",
      "    sklearn.base.TransformerMixin(sklearn.utils._set_output._SetOutputMixin)\n",
      "        sklearn.preprocessing._data.Binarizer(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._data.KernelCenterer(sklearn.base.ClassNamePrefixFeaturesOutMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._data.MaxAbsScaler(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._data.MinMaxScaler(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._data.Normalizer(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._data.PowerTransformer(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._data.QuantileTransformer(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._data.RobustScaler(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._data.StandardScaler(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._discretization.KBinsDiscretizer(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._function_transformer.FunctionTransformer(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._label.LabelBinarizer(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._label.LabelEncoder(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._label.MultiLabelBinarizer(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._polynomial.PolynomialFeatures(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._polynomial.SplineTransformer(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "    sklearn.preprocessing._encoders._BaseEncoder(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.preprocessing._encoders.OneHotEncoder\n",
      "        sklearn.preprocessing._encoders.OrdinalEncoder(sklearn.base.OneToOneFeatureMixin, sklearn.preprocessing._encoders._BaseEncoder)\n",
      "        sklearn.preprocessing._target_encoder.TargetEncoder(sklearn.base.OneToOneFeatureMixin, sklearn.preprocessing._encoders._BaseEncoder)\n",
      "\n",
      "    class Binarizer(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "     |  Binarizer(*, threshold=0.0, copy=True)\n",
      "     |\n",
      "     |  Binarize data (set feature values to 0 or 1) according to a threshold.\n",
      "     |\n",
      "     |  Values greater than the threshold map to 1, while values less than\n",
      "     |  or equal to the threshold map to 0. With the default threshold of 0,\n",
      "     |  only positive values map to 1.\n",
      "     |\n",
      "     |  Binarization is a common operation on text count data where the\n",
      "     |  analyst can decide to only consider the presence or absence of a\n",
      "     |  feature rather than a quantified number of occurrences for instance.\n",
      "     |\n",
      "     |  It can also be used as a pre-processing step for estimators that\n",
      "     |  consider boolean random variables (e.g. modelled using the Bernoulli\n",
      "     |  distribution in a Bayesian setting).\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <preprocessing_binarization>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  threshold : float, default=0.0\n",
      "     |      Feature values below or equal to this are replaced by 0, above it by 1.\n",
      "     |      Threshold may not be less than 0 for operations on sparse matrices.\n",
      "     |\n",
      "     |  copy : bool, default=True\n",
      "     |      Set to False to perform inplace binarization and avoid a copy (if\n",
      "     |      the input is already a numpy array or a scipy.sparse CSR matrix).\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  binarize : Equivalent function without the estimator API.\n",
      "     |  KBinsDiscretizer : Bin continuous data into intervals.\n",
      "     |  OneHotEncoder : Encode categorical features as a one-hot numeric array.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  If the input is a sparse matrix, only the non-zero values are subject\n",
      "     |  to update by the :class:`Binarizer` class.\n",
      "     |\n",
      "     |  This estimator is :term:`stateless` and does not need to be fitted.\n",
      "     |  However, we recommend to call :meth:`fit_transform` instead of\n",
      "     |  :meth:`transform`, as parameter validation is only performed in\n",
      "     |  :meth:`fit`.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.preprocessing import Binarizer\n",
      "     |  >>> X = [[ 1., -1.,  2.],\n",
      "     |  ...      [ 2.,  0.,  0.],\n",
      "     |  ...      [ 0.,  1., -1.]]\n",
      "     |  >>> transformer = Binarizer().fit(X)  # fit does nothing.\n",
      "     |  >>> transformer\n",
      "     |  Binarizer()\n",
      "     |  >>> transformer.transform(X)\n",
      "     |  array([[1., 0., 1.],\n",
      "     |         [1., 0., 0.],\n",
      "     |         [0., 1., 0.]])\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      Binarizer\n",
      "     |      sklearn.base.OneToOneFeatureMixin\n",
      "     |      sklearn.base.TransformerMixin\n",
      "     |      sklearn.utils._set_output._SetOutputMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, threshold=0.0, copy=True)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y=None)\n",
      "     |      Only validates estimator's parameters.\n",
      "     |\n",
      "     |      This method allows to: (i) validate the estimator's parameters and\n",
      "     |      (ii) be consistent with the scikit-learn transformer API.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data.\n",
      "     |\n",
      "     |      y : None\n",
      "     |          Ignored.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted transformer.\n",
      "     |\n",
      "     |  set_transform_request(self: sklearn.preprocessing._data.Binarizer, *, copy: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.preprocessing._data.Binarizer from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
      "     |      Request metadata passed to the ``transform`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``transform`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``transform``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      copy : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``copy`` parameter in ``transform``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  transform(self, X, copy=None)\n",
      "     |      Binarize each element of X.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data to binarize, element by element.\n",
      "     |          scipy.sparse matrices should be in CSR format to avoid an\n",
      "     |          un-necessary copy.\n",
      "     |\n",
      "     |      copy : bool\n",
      "     |          Copy the input X or not.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Transformed array.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.OneToOneFeatureMixin:\n",
      "     |\n",
      "     |  get_feature_names_out(self, input_features=None)\n",
      "     |      Get output feature names for transformation.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      input_features : array-like of str or None, default=None\n",
      "     |          Input features.\n",
      "     |\n",
      "     |          - If `input_features` is `None`, then `feature_names_in_` is\n",
      "     |            used as feature names in. If `feature_names_in_` is not defined,\n",
      "     |            then the following input feature names are generated:\n",
      "     |            `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n",
      "     |          - If `input_features` is an array-like, then `input_features` must\n",
      "     |            match `feature_names_in_` if `feature_names_in_` is defined.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      feature_names_out : ndarray of str objects\n",
      "     |          Same as input features.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.OneToOneFeatureMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.TransformerMixin:\n",
      "     |\n",
      "     |  fit_transform(self, X, y=None, **fit_params)\n",
      "     |      Fit to data, then transform it.\n",
      "     |\n",
      "     |      Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
      "     |      and returns a transformed version of `X`.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Input samples.\n",
      "     |\n",
      "     |      y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n",
      "     |          Target values (None for unsupervised transformations).\n",
      "     |\n",
      "     |      **fit_params : dict\n",
      "     |          Additional fit parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      "     |          Transformed array.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  set_output(self, *, transform=None)\n",
      "     |      Set output container.\n",
      "     |\n",
      "     |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      "     |      for an example on how to use the API.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      transform : {\"default\", \"pandas\", \"polars\"}, default=None\n",
      "     |          Configure output of `transform` and `fit_transform`.\n",
      "     |\n",
      "     |          - `\"default\"`: Default output format of a transformer\n",
      "     |          - `\"pandas\"`: DataFrame output\n",
      "     |          - `\"polars\"`: Polars output\n",
      "     |          - `None`: Transform configuration is unchanged\n",
      "     |\n",
      "     |          .. versionadded:: 1.4\n",
      "     |              `\"polars\"` option was added.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs)\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |\n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "\n",
      "    class FunctionTransformer(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "     |  FunctionTransformer(func=None, inverse_func=None, *, validate=False, accept_sparse=False, check_inverse=True, feature_names_out=None, kw_args=None, inv_kw_args=None)\n",
      "     |\n",
      "     |  Constructs a transformer from an arbitrary callable.\n",
      "     |\n",
      "     |  A FunctionTransformer forwards its X (and optionally y) arguments to a\n",
      "     |  user-defined function or function object and returns the result of this\n",
      "     |  function. This is useful for stateless transformations such as taking the\n",
      "     |  log of frequencies, doing custom scaling, etc.\n",
      "     |\n",
      "     |  Note: If a lambda is used as the function, then the resulting\n",
      "     |  transformer will not be pickleable.\n",
      "     |\n",
      "     |  .. versionadded:: 0.17\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <function_transformer>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  func : callable, default=None\n",
      "     |      The callable to use for the transformation. This will be passed\n",
      "     |      the same arguments as transform, with args and kwargs forwarded.\n",
      "     |      If func is None, then func will be the identity function.\n",
      "     |\n",
      "     |  inverse_func : callable, default=None\n",
      "     |      The callable to use for the inverse transformation. This will be\n",
      "     |      passed the same arguments as inverse transform, with args and\n",
      "     |      kwargs forwarded. If inverse_func is None, then inverse_func\n",
      "     |      will be the identity function.\n",
      "     |\n",
      "     |  validate : bool, default=False\n",
      "     |      Indicate that the input X array should be checked before calling\n",
      "     |      ``func``. The possibilities are:\n",
      "     |\n",
      "     |      - If False, there is no input validation.\n",
      "     |      - If True, then X will be converted to a 2-dimensional NumPy array or\n",
      "     |        sparse matrix. If the conversion is not possible an exception is\n",
      "     |        raised.\n",
      "     |\n",
      "     |      .. versionchanged:: 0.22\n",
      "     |         The default of ``validate`` changed from True to False.\n",
      "     |\n",
      "     |  accept_sparse : bool, default=False\n",
      "     |      Indicate that func accepts a sparse matrix as input. If validate is\n",
      "     |      False, this has no effect. Otherwise, if accept_sparse is false,\n",
      "     |      sparse matrix inputs will cause an exception to be raised.\n",
      "     |\n",
      "     |  check_inverse : bool, default=True\n",
      "     |     Whether to check that or ``func`` followed by ``inverse_func`` leads to\n",
      "     |     the original inputs. It can be used for a sanity check, raising a\n",
      "     |     warning when the condition is not fulfilled.\n",
      "     |\n",
      "     |     .. versionadded:: 0.20\n",
      "     |\n",
      "     |  feature_names_out : callable, 'one-to-one' or None, default=None\n",
      "     |      Determines the list of feature names that will be returned by the\n",
      "     |      `get_feature_names_out` method. If it is 'one-to-one', then the output\n",
      "     |      feature names will be equal to the input feature names. If it is a\n",
      "     |      callable, then it must take two positional arguments: this\n",
      "     |      `FunctionTransformer` (`self`) and an array-like of input feature names\n",
      "     |      (`input_features`). It must return an array-like of output feature\n",
      "     |      names. The `get_feature_names_out` method is only defined if\n",
      "     |      `feature_names_out` is not None.\n",
      "     |\n",
      "     |      See ``get_feature_names_out`` for more details.\n",
      "     |\n",
      "     |      .. versionadded:: 1.1\n",
      "     |\n",
      "     |  kw_args : dict, default=None\n",
      "     |      Dictionary of additional keyword arguments to pass to func.\n",
      "     |\n",
      "     |      .. versionadded:: 0.18\n",
      "     |\n",
      "     |  inv_kw_args : dict, default=None\n",
      "     |      Dictionary of additional keyword arguments to pass to inverse_func.\n",
      "     |\n",
      "     |      .. versionadded:: 0.18\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X` has feature\n",
      "     |      names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  MaxAbsScaler : Scale each feature by its maximum absolute value.\n",
      "     |  StandardScaler : Standardize features by removing the mean and\n",
      "     |      scaling to unit variance.\n",
      "     |  LabelBinarizer : Binarize labels in a one-vs-all fashion.\n",
      "     |  MultiLabelBinarizer : Transform between iterable of iterables\n",
      "     |      and a multilabel format.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  If `func` returns an output with a `columns` attribute, then the columns is enforced\n",
      "     |  to be consistent with the output of `get_feature_names_out`.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.preprocessing import FunctionTransformer\n",
      "     |  >>> transformer = FunctionTransformer(np.log1p)\n",
      "     |  >>> X = np.array([[0, 1], [2, 3]])\n",
      "     |  >>> transformer.transform(X)\n",
      "     |  array([[0.       , 0.6931...],\n",
      "     |         [1.0986..., 1.3862...]])\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      FunctionTransformer\n",
      "     |      sklearn.base.TransformerMixin\n",
      "     |      sklearn.utils._set_output._SetOutputMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, func=None, inverse_func=None, *, validate=False, accept_sparse=False, check_inverse=True, feature_names_out=None, kw_args=None, inv_kw_args=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  __sklearn_is_fitted__(self)\n",
      "     |      Return True since FunctionTransfomer is stateless.\n",
      "     |\n",
      "     |  fit(self, X, y=None)\n",
      "     |      Fit transformer by checking X.\n",
      "     |\n",
      "     |      If ``validate`` is ``True``, ``X`` will be checked.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse-matrix} of shape (n_samples, n_features)                 if `validate=True` else any object that `func` can handle\n",
      "     |          Input array.\n",
      "     |\n",
      "     |      y : Ignored\n",
      "     |          Not used, present here for API consistency by convention.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          FunctionTransformer class instance.\n",
      "     |\n",
      "     |  get_feature_names_out(self, input_features=None)\n",
      "     |      Get output feature names for transformation.\n",
      "     |\n",
      "     |      This method is only defined if `feature_names_out` is not None.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      input_features : array-like of str or None, default=None\n",
      "     |          Input feature names.\n",
      "     |\n",
      "     |          - If `input_features` is None, then `feature_names_in_` is\n",
      "     |            used as the input feature names. If `feature_names_in_` is not\n",
      "     |            defined, then names are generated:\n",
      "     |            `[x0, x1, ..., x(n_features_in_ - 1)]`.\n",
      "     |          - If `input_features` is array-like, then `input_features` must\n",
      "     |            match `feature_names_in_` if `feature_names_in_` is defined.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      feature_names_out : ndarray of str objects\n",
      "     |          Transformed feature names.\n",
      "     |\n",
      "     |          - If `feature_names_out` is 'one-to-one', the input feature names\n",
      "     |            are returned (see `input_features` above). This requires\n",
      "     |            `feature_names_in_` and/or `n_features_in_` to be defined, which\n",
      "     |            is done automatically if `validate=True`. Alternatively, you can\n",
      "     |            set them in `func`.\n",
      "     |          - If `feature_names_out` is a callable, then it is called with two\n",
      "     |            arguments, `self` and `input_features`, and its return value is\n",
      "     |            returned by this method.\n",
      "     |\n",
      "     |  inverse_transform(self, X)\n",
      "     |      Transform X using the inverse function.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse-matrix} of shape (n_samples, n_features)                 if `validate=True` else any object that `inverse_func` can handle\n",
      "     |          Input array.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_out : array-like, shape (n_samples, n_features)\n",
      "     |          Transformed input.\n",
      "     |\n",
      "     |  set_output(self, *, transform=None)\n",
      "     |      Set output container.\n",
      "     |\n",
      "     |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      "     |      for an example on how to use the API.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      transform : {\"default\", \"pandas\", \"polars\"}, default=None\n",
      "     |          Configure output of `transform` and `fit_transform`.\n",
      "     |\n",
      "     |          - `\"default\"`: Default output format of a transformer\n",
      "     |          - `\"pandas\"`: DataFrame output\n",
      "     |          - `\"polars\"`: Polars output\n",
      "     |          - `None`: Transform configuration is unchanged\n",
      "     |\n",
      "     |          .. versionadded:: 1.4\n",
      "     |              `\"polars\"` option was added.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  transform(self, X)\n",
      "     |      Transform X using the forward function.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse-matrix} of shape (n_samples, n_features)                 if `validate=True` else any object that `func` can handle\n",
      "     |          Input array.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_out : array-like, shape (n_samples, n_features)\n",
      "     |          Transformed input.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.TransformerMixin:\n",
      "     |\n",
      "     |  fit_transform(self, X, y=None, **fit_params)\n",
      "     |      Fit to data, then transform it.\n",
      "     |\n",
      "     |      Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
      "     |      and returns a transformed version of `X`.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Input samples.\n",
      "     |\n",
      "     |      y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n",
      "     |          Target values (None for unsupervised transformations).\n",
      "     |\n",
      "     |      **fit_params : dict\n",
      "     |          Additional fit parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      "     |          Transformed array.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs)\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "\n",
      "    class KBinsDiscretizer(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "     |  KBinsDiscretizer(n_bins=5, *, encode='onehot', strategy='quantile', dtype=None, subsample=200000, random_state=None)\n",
      "     |\n",
      "     |  Bin continuous data into intervals.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <preprocessing_discretization>`.\n",
      "     |\n",
      "     |  .. versionadded:: 0.20\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  n_bins : int or array-like of shape (n_features,), default=5\n",
      "     |      The number of bins to produce. Raises ValueError if ``n_bins < 2``.\n",
      "     |\n",
      "     |  encode : {'onehot', 'onehot-dense', 'ordinal'}, default='onehot'\n",
      "     |      Method used to encode the transformed result.\n",
      "     |\n",
      "     |      - 'onehot': Encode the transformed result with one-hot encoding\n",
      "     |        and return a sparse matrix. Ignored features are always\n",
      "     |        stacked to the right.\n",
      "     |      - 'onehot-dense': Encode the transformed result with one-hot encoding\n",
      "     |        and return a dense array. Ignored features are always\n",
      "     |        stacked to the right.\n",
      "     |      - 'ordinal': Return the bin identifier encoded as an integer value.\n",
      "     |\n",
      "     |  strategy : {'uniform', 'quantile', 'kmeans'}, default='quantile'\n",
      "     |      Strategy used to define the widths of the bins.\n",
      "     |\n",
      "     |      - 'uniform': All bins in each feature have identical widths.\n",
      "     |      - 'quantile': All bins in each feature have the same number of points.\n",
      "     |      - 'kmeans': Values in each bin have the same nearest center of a 1D\n",
      "     |        k-means cluster.\n",
      "     |\n",
      "     |      For an example of the different strategies see:\n",
      "     |      :ref:`sphx_glr_auto_examples_preprocessing_plot_discretization_strategies.py`.\n",
      "     |\n",
      "     |  dtype : {np.float32, np.float64}, default=None\n",
      "     |      The desired data-type for the output. If None, output dtype is\n",
      "     |      consistent with input dtype. Only np.float32 and np.float64 are\n",
      "     |      supported.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  subsample : int or None, default=200_000\n",
      "     |      Maximum number of samples, used to fit the model, for computational\n",
      "     |      efficiency.\n",
      "     |      `subsample=None` means that all the training samples are used when\n",
      "     |      computing the quantiles that determine the binning thresholds.\n",
      "     |      Since quantile computation relies on sorting each column of `X` and\n",
      "     |      that sorting has an `n log(n)` time complexity,\n",
      "     |      it is recommended to use subsampling on datasets with a\n",
      "     |      very large number of samples.\n",
      "     |\n",
      "     |      .. versionchanged:: 1.3\n",
      "     |          The default value of `subsample` changed from `None` to `200_000` when\n",
      "     |          `strategy=\"quantile\"`.\n",
      "     |\n",
      "     |      .. versionchanged:: 1.5\n",
      "     |          The default value of `subsample` changed from `None` to `200_000` when\n",
      "     |          `strategy=\"uniform\"` or `strategy=\"kmeans\"`.\n",
      "     |\n",
      "     |  random_state : int, RandomState instance or None, default=None\n",
      "     |      Determines random number generation for subsampling.\n",
      "     |      Pass an int for reproducible results across multiple function calls.\n",
      "     |      See the `subsample` parameter for more details.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |\n",
      "     |      .. versionadded:: 1.1\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  bin_edges_ : ndarray of ndarray of shape (n_features,)\n",
      "     |      The edges of each bin. Contain arrays of varying shapes ``(n_bins_, )``\n",
      "     |      Ignored features will have empty arrays.\n",
      "     |\n",
      "     |  n_bins_ : ndarray of shape (n_features,), dtype=np.int64\n",
      "     |      Number of bins per feature. Bins whose width are too small\n",
      "     |      (i.e., <= 1e-8) are removed with a warning.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  Binarizer : Class used to bin values as ``0`` or\n",
      "     |      ``1`` based on a parameter ``threshold``.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |\n",
      "     |  For a visualization of discretization on different datasets refer to\n",
      "     |  :ref:`sphx_glr_auto_examples_preprocessing_plot_discretization_classification.py`.\n",
      "     |  On the effect of discretization on linear models see:\n",
      "     |  :ref:`sphx_glr_auto_examples_preprocessing_plot_discretization.py`.\n",
      "     |\n",
      "     |  In bin edges for feature ``i``, the first and last values are used only for\n",
      "     |  ``inverse_transform``. During transform, bin edges are extended to::\n",
      "     |\n",
      "     |    np.concatenate([-np.inf, bin_edges_[i][1:-1], np.inf])\n",
      "     |\n",
      "     |  You can combine ``KBinsDiscretizer`` with\n",
      "     |  :class:`~sklearn.compose.ColumnTransformer` if you only want to preprocess\n",
      "     |  part of the features.\n",
      "     |\n",
      "     |  ``KBinsDiscretizer`` might produce constant features (e.g., when\n",
      "     |  ``encode = 'onehot'`` and certain bins do not contain any data).\n",
      "     |  These features can be removed with feature selection algorithms\n",
      "     |  (e.g., :class:`~sklearn.feature_selection.VarianceThreshold`).\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.preprocessing import KBinsDiscretizer\n",
      "     |  >>> X = [[-2, 1, -4,   -1],\n",
      "     |  ...      [-1, 2, -3, -0.5],\n",
      "     |  ...      [ 0, 3, -2,  0.5],\n",
      "     |  ...      [ 1, 4, -1,    2]]\n",
      "     |  >>> est = KBinsDiscretizer(\n",
      "     |  ...     n_bins=3, encode='ordinal', strategy='uniform'\n",
      "     |  ... )\n",
      "     |  >>> est.fit(X)\n",
      "     |  KBinsDiscretizer(...)\n",
      "     |  >>> Xt = est.transform(X)\n",
      "     |  >>> Xt  # doctest: +SKIP\n",
      "     |  array([[ 0., 0., 0., 0.],\n",
      "     |         [ 1., 1., 1., 0.],\n",
      "     |         [ 2., 2., 2., 1.],\n",
      "     |         [ 2., 2., 2., 2.]])\n",
      "     |\n",
      "     |  Sometimes it may be useful to convert the data back into the original\n",
      "     |  feature space. The ``inverse_transform`` function converts the binned\n",
      "     |  data into the original feature space. Each value will be equal to the mean\n",
      "     |  of the two bin edges.\n",
      "     |\n",
      "     |  >>> est.bin_edges_[0]\n",
      "     |  array([-2., -1.,  0.,  1.])\n",
      "     |  >>> est.inverse_transform(Xt)\n",
      "     |  array([[-1.5,  1.5, -3.5, -0.5],\n",
      "     |         [-0.5,  2.5, -2.5, -0.5],\n",
      "     |         [ 0.5,  3.5, -1.5,  0.5],\n",
      "     |         [ 0.5,  3.5, -1.5,  1.5]])\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      KBinsDiscretizer\n",
      "     |      sklearn.base.TransformerMixin\n",
      "     |      sklearn.utils._set_output._SetOutputMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, n_bins=5, *, encode='onehot', strategy='quantile', dtype=None, subsample=200000, random_state=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y=None, sample_weight=None)\n",
      "     |      Fit the estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Data to be discretized.\n",
      "     |\n",
      "     |      y : None\n",
      "     |          Ignored. This parameter exists only for compatibility with\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`.\n",
      "     |\n",
      "     |      sample_weight : ndarray of shape (n_samples,)\n",
      "     |          Contains weight values to be associated with each sample.\n",
      "     |          Cannot be used when `strategy` is set to `\"uniform\"`.\n",
      "     |\n",
      "     |          .. versionadded:: 1.3\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns the instance itself.\n",
      "     |\n",
      "     |  get_feature_names_out(self, input_features=None)\n",
      "     |      Get output feature names.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      input_features : array-like of str or None, default=None\n",
      "     |          Input features.\n",
      "     |\n",
      "     |          - If `input_features` is `None`, then `feature_names_in_` is\n",
      "     |            used as feature names in. If `feature_names_in_` is not defined,\n",
      "     |            then the following input feature names are generated:\n",
      "     |            `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n",
      "     |          - If `input_features` is an array-like, then `input_features` must\n",
      "     |            match `feature_names_in_` if `feature_names_in_` is defined.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      feature_names_out : ndarray of str objects\n",
      "     |          Transformed feature names.\n",
      "     |\n",
      "     |  inverse_transform(self, X=None, *, Xt=None)\n",
      "     |      Transform discretized data back to original feature space.\n",
      "     |\n",
      "     |      Note that this function does not regenerate the original data\n",
      "     |      due to discretization rounding.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Transformed data in the binned space.\n",
      "     |\n",
      "     |      Xt : array-like of shape (n_samples, n_features)\n",
      "     |          Transformed data in the binned space.\n",
      "     |\n",
      "     |          .. deprecated:: 1.5\n",
      "     |              `Xt` was deprecated in 1.5 and will be removed in 1.7. Use `X` instead.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Xinv : ndarray, dtype={np.float32, np.float64}\n",
      "     |          Data in the original feature space.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.preprocessing._discretization.KBinsDiscretizer, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.preprocessing._discretization.KBinsDiscretizer from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  transform(self, X)\n",
      "     |      Discretize the data.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Data to be discretized.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Xt : {ndarray, sparse matrix}, dtype={np.float32, np.float64}\n",
      "     |          Data in the binned space. Will be a sparse matrix if\n",
      "     |          `self.encode='onehot'` and ndarray otherwise.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.TransformerMixin:\n",
      "     |\n",
      "     |  fit_transform(self, X, y=None, **fit_params)\n",
      "     |      Fit to data, then transform it.\n",
      "     |\n",
      "     |      Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
      "     |      and returns a transformed version of `X`.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Input samples.\n",
      "     |\n",
      "     |      y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n",
      "     |          Target values (None for unsupervised transformations).\n",
      "     |\n",
      "     |      **fit_params : dict\n",
      "     |          Additional fit parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      "     |          Transformed array.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  set_output(self, *, transform=None)\n",
      "     |      Set output container.\n",
      "     |\n",
      "     |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      "     |      for an example on how to use the API.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      transform : {\"default\", \"pandas\", \"polars\"}, default=None\n",
      "     |          Configure output of `transform` and `fit_transform`.\n",
      "     |\n",
      "     |          - `\"default\"`: Default output format of a transformer\n",
      "     |          - `\"pandas\"`: DataFrame output\n",
      "     |          - `\"polars\"`: Polars output\n",
      "     |          - `None`: Transform configuration is unchanged\n",
      "     |\n",
      "     |          .. versionadded:: 1.4\n",
      "     |              `\"polars\"` option was added.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs)\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "\n",
      "    class KernelCenterer(sklearn.base.ClassNamePrefixFeaturesOutMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "     |  Center an arbitrary kernel matrix :math:`K`.\n",
      "     |\n",
      "     |  Let define a kernel :math:`K` such that:\n",
      "     |\n",
      "     |  .. math::\n",
      "     |      K(X, Y) = \\phi(X) . \\phi(Y)^{T}\n",
      "     |\n",
      "     |  :math:`\\phi(X)` is a function mapping of rows of :math:`X` to a\n",
      "     |  Hilbert space and :math:`K` is of shape `(n_samples, n_samples)`.\n",
      "     |\n",
      "     |  This class allows to compute :math:`\\tilde{K}(X, Y)` such that:\n",
      "     |\n",
      "     |  .. math::\n",
      "     |      \\tilde{K(X, Y)} = \\tilde{\\phi}(X) . \\tilde{\\phi}(Y)^{T}\n",
      "     |\n",
      "     |  :math:`\\tilde{\\phi}(X)` is the centered mapped data in the Hilbert\n",
      "     |  space.\n",
      "     |\n",
      "     |  `KernelCenterer` centers the features without explicitly computing the\n",
      "     |  mapping :math:`\\phi(\\cdot)`. Working with centered kernels is sometime\n",
      "     |  expected when dealing with algebra computation such as eigendecomposition\n",
      "     |  for :class:`~sklearn.decomposition.KernelPCA` for instance.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <kernel_centering>`.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  K_fit_rows_ : ndarray of shape (n_samples,)\n",
      "     |      Average of each column of kernel matrix.\n",
      "     |\n",
      "     |  K_fit_all_ : float\n",
      "     |      Average of kernel matrix.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  sklearn.kernel_approximation.Nystroem : Approximate a kernel map\n",
      "     |      using a subset of the training data.\n",
      "     |\n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  .. [1] `Schölkopf, Bernhard, Alexander Smola, and Klaus-Robert Müller.\n",
      "     |     \"Nonlinear component analysis as a kernel eigenvalue problem.\"\n",
      "     |     Neural computation 10.5 (1998): 1299-1319.\n",
      "     |     <https://www.mlpack.org/papers/kpca.pdf>`_\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.preprocessing import KernelCenterer\n",
      "     |  >>> from sklearn.metrics.pairwise import pairwise_kernels\n",
      "     |  >>> X = [[ 1., -2.,  2.],\n",
      "     |  ...      [ -2.,  1.,  3.],\n",
      "     |  ...      [ 4.,  1., -2.]]\n",
      "     |  >>> K = pairwise_kernels(X, metric='linear')\n",
      "     |  >>> K\n",
      "     |  array([[  9.,   2.,  -2.],\n",
      "     |         [  2.,  14., -13.],\n",
      "     |         [ -2., -13.,  21.]])\n",
      "     |  >>> transformer = KernelCenterer().fit(K)\n",
      "     |  >>> transformer\n",
      "     |  KernelCenterer()\n",
      "     |  >>> transformer.transform(K)\n",
      "     |  array([[  5.,   0.,  -5.],\n",
      "     |         [  0.,  14., -14.],\n",
      "     |         [ -5., -14.,  19.]])\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      KernelCenterer\n",
      "     |      sklearn.base.ClassNamePrefixFeaturesOutMixin\n",
      "     |      sklearn.base.TransformerMixin\n",
      "     |      sklearn.utils._set_output._SetOutputMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, K, y=None)\n",
      "     |      Fit KernelCenterer.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      K : ndarray of shape (n_samples, n_samples)\n",
      "     |          Kernel matrix.\n",
      "     |\n",
      "     |      y : None\n",
      "     |          Ignored.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns the instance itself.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.preprocessing._data.KernelCenterer, *, K: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.preprocessing._data.KernelCenterer from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      K : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``K`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_transform_request(self: sklearn.preprocessing._data.KernelCenterer, *, K: Union[bool, NoneType, str] = '$UNCHANGED$', copy: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.preprocessing._data.KernelCenterer from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
      "     |      Request metadata passed to the ``transform`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``transform`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``transform``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      K : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``K`` parameter in ``transform``.\n",
      "     |\n",
      "     |      copy : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``copy`` parameter in ``transform``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  transform(self, K, copy=True)\n",
      "     |      Center kernel matrix.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      K : ndarray of shape (n_samples1, n_samples2)\n",
      "     |          Kernel matrix.\n",
      "     |\n",
      "     |      copy : bool, default=True\n",
      "     |          Set to False to perform inplace computation.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      K_new : ndarray of shape (n_samples1, n_samples2)\n",
      "     |          Returns the instance itself.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.ClassNamePrefixFeaturesOutMixin:\n",
      "     |\n",
      "     |  get_feature_names_out(self, input_features=None)\n",
      "     |      Get output feature names for transformation.\n",
      "     |\n",
      "     |      The feature names out will prefixed by the lowercased class name. For\n",
      "     |      example, if the transformer outputs 3 features, then the feature names\n",
      "     |      out are: `[\"class_name0\", \"class_name1\", \"class_name2\"]`.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      input_features : array-like of str or None, default=None\n",
      "     |          Only used to validate feature names with the names seen in `fit`.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      feature_names_out : ndarray of str objects\n",
      "     |          Transformed feature names.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.ClassNamePrefixFeaturesOutMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.TransformerMixin:\n",
      "     |\n",
      "     |  fit_transform(self, X, y=None, **fit_params)\n",
      "     |      Fit to data, then transform it.\n",
      "     |\n",
      "     |      Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
      "     |      and returns a transformed version of `X`.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Input samples.\n",
      "     |\n",
      "     |      y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n",
      "     |          Target values (None for unsupervised transformations).\n",
      "     |\n",
      "     |      **fit_params : dict\n",
      "     |          Additional fit parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      "     |          Transformed array.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  set_output(self, *, transform=None)\n",
      "     |      Set output container.\n",
      "     |\n",
      "     |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      "     |      for an example on how to use the API.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      transform : {\"default\", \"pandas\", \"polars\"}, default=None\n",
      "     |          Configure output of `transform` and `fit_transform`.\n",
      "     |\n",
      "     |          - `\"default\"`: Default output format of a transformer\n",
      "     |          - `\"pandas\"`: DataFrame output\n",
      "     |          - `\"polars\"`: Polars output\n",
      "     |          - `None`: Transform configuration is unchanged\n",
      "     |\n",
      "     |          .. versionadded:: 1.4\n",
      "     |              `\"polars\"` option was added.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs)\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |\n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "\n",
      "    class LabelBinarizer(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "     |  LabelBinarizer(*, neg_label=0, pos_label=1, sparse_output=False)\n",
      "     |\n",
      "     |  Binarize labels in a one-vs-all fashion.\n",
      "     |\n",
      "     |  Several regression and binary classification algorithms are\n",
      "     |  available in scikit-learn. A simple way to extend these algorithms\n",
      "     |  to the multi-class classification case is to use the so-called\n",
      "     |  one-vs-all scheme.\n",
      "     |\n",
      "     |  At learning time, this simply consists in learning one regressor\n",
      "     |  or binary classifier per class. In doing so, one needs to convert\n",
      "     |  multi-class labels to binary labels (belong or does not belong\n",
      "     |  to the class). `LabelBinarizer` makes this process easy with the\n",
      "     |  transform method.\n",
      "     |\n",
      "     |  At prediction time, one assigns the class for which the corresponding\n",
      "     |  model gave the greatest confidence. `LabelBinarizer` makes this easy\n",
      "     |  with the :meth:`inverse_transform` method.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <preprocessing_targets>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  neg_label : int, default=0\n",
      "     |      Value with which negative labels must be encoded.\n",
      "     |\n",
      "     |  pos_label : int, default=1\n",
      "     |      Value with which positive labels must be encoded.\n",
      "     |\n",
      "     |  sparse_output : bool, default=False\n",
      "     |      True if the returned array from transform is desired to be in sparse\n",
      "     |      CSR format.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  classes_ : ndarray of shape (n_classes,)\n",
      "     |      Holds the label for each class.\n",
      "     |\n",
      "     |  y_type_ : str\n",
      "     |      Represents the type of the target data as evaluated by\n",
      "     |      :func:`~sklearn.utils.multiclass.type_of_target`. Possible type are\n",
      "     |      'continuous', 'continuous-multioutput', 'binary', 'multiclass',\n",
      "     |      'multiclass-multioutput', 'multilabel-indicator', and 'unknown'.\n",
      "     |\n",
      "     |  sparse_input_ : bool\n",
      "     |      `True` if the input data to transform is given as a sparse matrix,\n",
      "     |       `False` otherwise.\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  label_binarize : Function to perform the transform operation of\n",
      "     |      LabelBinarizer with fixed classes.\n",
      "     |  OneHotEncoder : Encode categorical features using a one-hot aka one-of-K\n",
      "     |      scheme.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.preprocessing import LabelBinarizer\n",
      "     |  >>> lb = LabelBinarizer()\n",
      "     |  >>> lb.fit([1, 2, 6, 4, 2])\n",
      "     |  LabelBinarizer()\n",
      "     |  >>> lb.classes_\n",
      "     |  array([1, 2, 4, 6])\n",
      "     |  >>> lb.transform([1, 6])\n",
      "     |  array([[1, 0, 0, 0],\n",
      "     |         [0, 0, 0, 1]])\n",
      "     |\n",
      "     |  Binary targets transform to a column vector\n",
      "     |\n",
      "     |  >>> lb = LabelBinarizer()\n",
      "     |  >>> lb.fit_transform(['yes', 'no', 'no', 'yes'])\n",
      "     |  array([[1],\n",
      "     |         [0],\n",
      "     |         [0],\n",
      "     |         [1]])\n",
      "     |\n",
      "     |  Passing a 2D matrix for multilabel classification\n",
      "     |\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> lb.fit(np.array([[0, 1, 1], [1, 0, 0]]))\n",
      "     |  LabelBinarizer()\n",
      "     |  >>> lb.classes_\n",
      "     |  array([0, 1, 2])\n",
      "     |  >>> lb.transform([0, 1, 2, 1])\n",
      "     |  array([[1, 0, 0],\n",
      "     |         [0, 1, 0],\n",
      "     |         [0, 0, 1],\n",
      "     |         [0, 1, 0]])\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      LabelBinarizer\n",
      "     |      sklearn.base.TransformerMixin\n",
      "     |      sklearn.utils._set_output._SetOutputMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, neg_label=0, pos_label=1, sparse_output=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, y)\n",
      "     |      Fit label binarizer.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      y : ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
      "     |          Target values. The 2-d matrix should only contain 0 and 1,\n",
      "     |          represents multilabel classification.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Returns the instance itself.\n",
      "     |\n",
      "     |  fit_transform(self, y)\n",
      "     |      Fit label binarizer/transform multi-class labels to binary labels.\n",
      "     |\n",
      "     |      The output of transform is sometimes referred to as\n",
      "     |      the 1-of-K coding scheme.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      y : {ndarray, sparse matrix} of shape (n_samples,) or                 (n_samples, n_classes)\n",
      "     |          Target values. The 2-d matrix should only contain 0 and 1,\n",
      "     |          represents multilabel classification. Sparse matrix can be\n",
      "     |          CSR, CSC, COO, DOK, or LIL.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Y : {ndarray, sparse matrix} of shape (n_samples, n_classes)\n",
      "     |          Shape will be (n_samples, 1) for binary problems. Sparse matrix\n",
      "     |          will be of CSR format.\n",
      "     |\n",
      "     |  inverse_transform(self, Y, threshold=None)\n",
      "     |      Transform binary labels back to multi-class labels.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      Y : {ndarray, sparse matrix} of shape (n_samples, n_classes)\n",
      "     |          Target values. All sparse matrices are converted to CSR before\n",
      "     |          inverse transformation.\n",
      "     |\n",
      "     |      threshold : float, default=None\n",
      "     |          Threshold used in the binary and multi-label cases.\n",
      "     |\n",
      "     |          Use 0 when ``Y`` contains the output of :term:`decision_function`\n",
      "     |          (classifier).\n",
      "     |          Use 0.5 when ``Y`` contains the output of :term:`predict_proba`.\n",
      "     |\n",
      "     |          If None, the threshold is assumed to be half way between\n",
      "     |          neg_label and pos_label.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : {ndarray, sparse matrix} of shape (n_samples,)\n",
      "     |          Target values. Sparse matrix will be of CSR format.\n",
      "     |\n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      In the case when the binary labels are fractional\n",
      "     |      (probabilistic), :meth:`inverse_transform` chooses the class with the\n",
      "     |      greatest value. Typically, this allows to use the output of a\n",
      "     |      linear model's :term:`decision_function` method directly as the input\n",
      "     |      of :meth:`inverse_transform`.\n",
      "     |\n",
      "     |  set_inverse_transform_request(self: sklearn.preprocessing._label.LabelBinarizer, *, threshold: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.preprocessing._label.LabelBinarizer from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
      "     |      Request metadata passed to the ``inverse_transform`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``inverse_transform`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``inverse_transform``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      threshold : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``threshold`` parameter in ``inverse_transform``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  transform(self, y)\n",
      "     |      Transform multi-class labels to binary labels.\n",
      "     |\n",
      "     |      The output of transform is sometimes referred to by some authors as\n",
      "     |      the 1-of-K coding scheme.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      y : {array, sparse matrix} of shape (n_samples,) or                 (n_samples, n_classes)\n",
      "     |          Target values. The 2-d matrix should only contain 0 and 1,\n",
      "     |          represents multilabel classification. Sparse matrix can be\n",
      "     |          CSR, CSC, COO, DOK, or LIL.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Y : {ndarray, sparse matrix} of shape (n_samples, n_classes)\n",
      "     |          Shape will be (n_samples, 1) for binary problems. Sparse matrix\n",
      "     |          will be of CSR format.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  set_output(self, *, transform=None)\n",
      "     |      Set output container.\n",
      "     |\n",
      "     |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      "     |      for an example on how to use the API.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      transform : {\"default\", \"pandas\", \"polars\"}, default=None\n",
      "     |          Configure output of `transform` and `fit_transform`.\n",
      "     |\n",
      "     |          - `\"default\"`: Default output format of a transformer\n",
      "     |          - `\"pandas\"`: DataFrame output\n",
      "     |          - `\"polars\"`: Polars output\n",
      "     |          - `None`: Transform configuration is unchanged\n",
      "     |\n",
      "     |          .. versionadded:: 1.4\n",
      "     |              `\"polars\"` option was added.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs)\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "\n",
      "    class LabelEncoder(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "     |  Encode target labels with value between 0 and n_classes-1.\n",
      "     |\n",
      "     |  This transformer should be used to encode target values, *i.e.* `y`, and\n",
      "     |  not the input `X`.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <preprocessing_targets>`.\n",
      "     |\n",
      "     |  .. versionadded:: 0.12\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  classes_ : ndarray of shape (n_classes,)\n",
      "     |      Holds the label for each class.\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  OrdinalEncoder : Encode categorical features using an ordinal encoding\n",
      "     |      scheme.\n",
      "     |  OneHotEncoder : Encode categorical features as a one-hot numeric array.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  `LabelEncoder` can be used to normalize labels.\n",
      "     |\n",
      "     |  >>> from sklearn.preprocessing import LabelEncoder\n",
      "     |  >>> le = LabelEncoder()\n",
      "     |  >>> le.fit([1, 2, 2, 6])\n",
      "     |  LabelEncoder()\n",
      "     |  >>> le.classes_\n",
      "     |  array([1, 2, 6])\n",
      "     |  >>> le.transform([1, 1, 2, 6])\n",
      "     |  array([0, 0, 1, 2]...)\n",
      "     |  >>> le.inverse_transform([0, 0, 1, 2])\n",
      "     |  array([1, 1, 2, 6])\n",
      "     |\n",
      "     |  It can also be used to transform non-numerical labels (as long as they are\n",
      "     |  hashable and comparable) to numerical labels.\n",
      "     |\n",
      "     |  >>> le = LabelEncoder()\n",
      "     |  >>> le.fit([\"paris\", \"paris\", \"tokyo\", \"amsterdam\"])\n",
      "     |  LabelEncoder()\n",
      "     |  >>> list(le.classes_)\n",
      "     |  [np.str_('amsterdam'), np.str_('paris'), np.str_('tokyo')]\n",
      "     |  >>> le.transform([\"tokyo\", \"tokyo\", \"paris\"])\n",
      "     |  array([2, 2, 1]...)\n",
      "     |  >>> list(le.inverse_transform([2, 2, 1]))\n",
      "     |  [np.str_('tokyo'), np.str_('tokyo'), np.str_('paris')]\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      LabelEncoder\n",
      "     |      sklearn.base.TransformerMixin\n",
      "     |      sklearn.utils._set_output._SetOutputMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  fit(self, y)\n",
      "     |      Fit label encoder.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : returns an instance of self.\n",
      "     |          Fitted label encoder.\n",
      "     |\n",
      "     |  fit_transform(self, y)\n",
      "     |      Fit label encoder and return encoded labels.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Encoded labels.\n",
      "     |\n",
      "     |  inverse_transform(self, y)\n",
      "     |      Transform labels back to original encoding.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      y : ndarray of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : ndarray of shape (n_samples,)\n",
      "     |          Original encoding.\n",
      "     |\n",
      "     |  transform(self, y)\n",
      "     |      Transform labels to normalized encoding.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Labels as normalized encodings.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  set_output(self, *, transform=None)\n",
      "     |      Set output container.\n",
      "     |\n",
      "     |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      "     |      for an example on how to use the API.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      transform : {\"default\", \"pandas\", \"polars\"}, default=None\n",
      "     |          Configure output of `transform` and `fit_transform`.\n",
      "     |\n",
      "     |          - `\"default\"`: Default output format of a transformer\n",
      "     |          - `\"pandas\"`: DataFrame output\n",
      "     |          - `\"polars\"`: Polars output\n",
      "     |          - `None`: Transform configuration is unchanged\n",
      "     |\n",
      "     |          .. versionadded:: 1.4\n",
      "     |              `\"polars\"` option was added.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs)\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "\n",
      "    class MaxAbsScaler(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "     |  MaxAbsScaler(*, copy=True)\n",
      "     |\n",
      "     |  Scale each feature by its maximum absolute value.\n",
      "     |\n",
      "     |  This estimator scales and translates each feature individually such\n",
      "     |  that the maximal absolute value of each feature in the\n",
      "     |  training set will be 1.0. It does not shift/center the data, and\n",
      "     |  thus does not destroy any sparsity.\n",
      "     |\n",
      "     |  This scaler can also be applied to sparse CSR or CSC matrices.\n",
      "     |\n",
      "     |  `MaxAbsScaler` doesn't reduce the effect of outliers; it only linearly\n",
      "     |  scales them down. For an example visualization, refer to :ref:`Compare\n",
      "     |  MaxAbsScaler with other scalers <plot_all_scaling_max_abs_scaler_section>`.\n",
      "     |\n",
      "     |  .. versionadded:: 0.17\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  copy : bool, default=True\n",
      "     |      Set to False to perform inplace scaling and avoid a copy (if the input\n",
      "     |      is already a numpy array).\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  scale_ : ndarray of shape (n_features,)\n",
      "     |      Per feature relative scaling of the data.\n",
      "     |\n",
      "     |      .. versionadded:: 0.17\n",
      "     |         *scale_* attribute.\n",
      "     |\n",
      "     |  max_abs_ : ndarray of shape (n_features,)\n",
      "     |      Per feature maximum absolute value.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  n_samples_seen_ : int\n",
      "     |      The number of samples processed by the estimator. Will be reset on\n",
      "     |      new calls to fit, but increments across ``partial_fit`` calls.\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  maxabs_scale : Equivalent function without the estimator API.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  NaNs are treated as missing values: disregarded in fit, and maintained in\n",
      "     |  transform.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.preprocessing import MaxAbsScaler\n",
      "     |  >>> X = [[ 1., -1.,  2.],\n",
      "     |  ...      [ 2.,  0.,  0.],\n",
      "     |  ...      [ 0.,  1., -1.]]\n",
      "     |  >>> transformer = MaxAbsScaler().fit(X)\n",
      "     |  >>> transformer\n",
      "     |  MaxAbsScaler()\n",
      "     |  >>> transformer.transform(X)\n",
      "     |  array([[ 0.5, -1. ,  1. ],\n",
      "     |         [ 1. ,  0. ,  0. ],\n",
      "     |         [ 0. ,  1. , -0.5]])\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      MaxAbsScaler\n",
      "     |      sklearn.base.OneToOneFeatureMixin\n",
      "     |      sklearn.base.TransformerMixin\n",
      "     |      sklearn.utils._set_output._SetOutputMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, copy=True)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y=None)\n",
      "     |      Compute the maximum absolute value to be used for later scaling.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data used to compute the per-feature minimum and maximum\n",
      "     |          used for later scaling along the features axis.\n",
      "     |\n",
      "     |      y : None\n",
      "     |          Ignored.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted scaler.\n",
      "     |\n",
      "     |  inverse_transform(self, X)\n",
      "     |      Scale back the data to the original representation.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data that should be transformed back.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Transformed array.\n",
      "     |\n",
      "     |  partial_fit(self, X, y=None)\n",
      "     |      Online computation of max absolute value of X for later scaling.\n",
      "     |\n",
      "     |      All of X is processed as a single batch. This is intended for cases\n",
      "     |      when :meth:`fit` is not feasible due to very large number of\n",
      "     |      `n_samples` or because X is read from a continuous stream.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data used to compute the mean and standard deviation\n",
      "     |          used for later scaling along the features axis.\n",
      "     |\n",
      "     |      y : None\n",
      "     |          Ignored.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted scaler.\n",
      "     |\n",
      "     |  transform(self, X)\n",
      "     |      Scale the data.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data that should be scaled.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Transformed array.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.OneToOneFeatureMixin:\n",
      "     |\n",
      "     |  get_feature_names_out(self, input_features=None)\n",
      "     |      Get output feature names for transformation.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      input_features : array-like of str or None, default=None\n",
      "     |          Input features.\n",
      "     |\n",
      "     |          - If `input_features` is `None`, then `feature_names_in_` is\n",
      "     |            used as feature names in. If `feature_names_in_` is not defined,\n",
      "     |            then the following input feature names are generated:\n",
      "     |            `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n",
      "     |          - If `input_features` is an array-like, then `input_features` must\n",
      "     |            match `feature_names_in_` if `feature_names_in_` is defined.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      feature_names_out : ndarray of str objects\n",
      "     |          Same as input features.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.OneToOneFeatureMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.TransformerMixin:\n",
      "     |\n",
      "     |  fit_transform(self, X, y=None, **fit_params)\n",
      "     |      Fit to data, then transform it.\n",
      "     |\n",
      "     |      Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
      "     |      and returns a transformed version of `X`.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Input samples.\n",
      "     |\n",
      "     |      y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n",
      "     |          Target values (None for unsupervised transformations).\n",
      "     |\n",
      "     |      **fit_params : dict\n",
      "     |          Additional fit parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      "     |          Transformed array.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  set_output(self, *, transform=None)\n",
      "     |      Set output container.\n",
      "     |\n",
      "     |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      "     |      for an example on how to use the API.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      transform : {\"default\", \"pandas\", \"polars\"}, default=None\n",
      "     |          Configure output of `transform` and `fit_transform`.\n",
      "     |\n",
      "     |          - `\"default\"`: Default output format of a transformer\n",
      "     |          - `\"pandas\"`: DataFrame output\n",
      "     |          - `\"polars\"`: Polars output\n",
      "     |          - `None`: Transform configuration is unchanged\n",
      "     |\n",
      "     |          .. versionadded:: 1.4\n",
      "     |              `\"polars\"` option was added.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs)\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |\n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "\n",
      "    class MinMaxScaler(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "     |  MinMaxScaler(feature_range=(0, 1), *, copy=True, clip=False)\n",
      "     |\n",
      "     |  Transform features by scaling each feature to a given range.\n",
      "     |\n",
      "     |  This estimator scales and translates each feature individually such\n",
      "     |  that it is in the given range on the training set, e.g. between\n",
      "     |  zero and one.\n",
      "     |\n",
      "     |  The transformation is given by::\n",
      "     |\n",
      "     |      X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
      "     |      X_scaled = X_std * (max - min) + min\n",
      "     |\n",
      "     |  where min, max = feature_range.\n",
      "     |\n",
      "     |  This transformation is often used as an alternative to zero mean,\n",
      "     |  unit variance scaling.\n",
      "     |\n",
      "     |  `MinMaxScaler` doesn't reduce the effect of outliers, but it linearly\n",
      "     |  scales them down into a fixed range, where the largest occurring data point\n",
      "     |  corresponds to the maximum value and the smallest one corresponds to the\n",
      "     |  minimum value. For an example visualization, refer to :ref:`Compare\n",
      "     |  MinMaxScaler with other scalers <plot_all_scaling_minmax_scaler_section>`.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <preprocessing_scaler>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  feature_range : tuple (min, max), default=(0, 1)\n",
      "     |      Desired range of transformed data.\n",
      "     |\n",
      "     |  copy : bool, default=True\n",
      "     |      Set to False to perform inplace row normalization and avoid a\n",
      "     |      copy (if the input is already a numpy array).\n",
      "     |\n",
      "     |  clip : bool, default=False\n",
      "     |      Set to True to clip transformed values of held-out data to\n",
      "     |      provided `feature range`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  min_ : ndarray of shape (n_features,)\n",
      "     |      Per feature adjustment for minimum. Equivalent to\n",
      "     |      ``min - X.min(axis=0) * self.scale_``\n",
      "     |\n",
      "     |  scale_ : ndarray of shape (n_features,)\n",
      "     |      Per feature relative scaling of the data. Equivalent to\n",
      "     |      ``(max - min) / (X.max(axis=0) - X.min(axis=0))``\n",
      "     |\n",
      "     |      .. versionadded:: 0.17\n",
      "     |         *scale_* attribute.\n",
      "     |\n",
      "     |  data_min_ : ndarray of shape (n_features,)\n",
      "     |      Per feature minimum seen in the data\n",
      "     |\n",
      "     |      .. versionadded:: 0.17\n",
      "     |         *data_min_*\n",
      "     |\n",
      "     |  data_max_ : ndarray of shape (n_features,)\n",
      "     |      Per feature maximum seen in the data\n",
      "     |\n",
      "     |      .. versionadded:: 0.17\n",
      "     |         *data_max_*\n",
      "     |\n",
      "     |  data_range_ : ndarray of shape (n_features,)\n",
      "     |      Per feature range ``(data_max_ - data_min_)`` seen in the data\n",
      "     |\n",
      "     |      .. versionadded:: 0.17\n",
      "     |         *data_range_*\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  n_samples_seen_ : int\n",
      "     |      The number of samples processed by the estimator.\n",
      "     |      It will be reset on new calls to fit, but increments across\n",
      "     |      ``partial_fit`` calls.\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  minmax_scale : Equivalent function without the estimator API.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  NaNs are treated as missing values: disregarded in fit, and maintained in\n",
      "     |  transform.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.preprocessing import MinMaxScaler\n",
      "     |  >>> data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
      "     |  >>> scaler = MinMaxScaler()\n",
      "     |  >>> print(scaler.fit(data))\n",
      "     |  MinMaxScaler()\n",
      "     |  >>> print(scaler.data_max_)\n",
      "     |  [ 1. 18.]\n",
      "     |  >>> print(scaler.transform(data))\n",
      "     |  [[0.   0.  ]\n",
      "     |   [0.25 0.25]\n",
      "     |   [0.5  0.5 ]\n",
      "     |   [1.   1.  ]]\n",
      "     |  >>> print(scaler.transform([[2, 2]]))\n",
      "     |  [[1.5 0. ]]\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      MinMaxScaler\n",
      "     |      sklearn.base.OneToOneFeatureMixin\n",
      "     |      sklearn.base.TransformerMixin\n",
      "     |      sklearn.utils._set_output._SetOutputMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, feature_range=(0, 1), *, copy=True, clip=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y=None)\n",
      "     |      Compute the minimum and maximum to be used for later scaling.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The data used to compute the per-feature minimum and maximum\n",
      "     |          used for later scaling along the features axis.\n",
      "     |\n",
      "     |      y : None\n",
      "     |          Ignored.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted scaler.\n",
      "     |\n",
      "     |  inverse_transform(self, X)\n",
      "     |      Undo the scaling of X according to feature_range.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Input data that will be transformed. It cannot be sparse.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Xt : ndarray of shape (n_samples, n_features)\n",
      "     |          Transformed data.\n",
      "     |\n",
      "     |  partial_fit(self, X, y=None)\n",
      "     |      Online computation of min and max on X for later scaling.\n",
      "     |\n",
      "     |      All of X is processed as a single batch. This is intended for cases\n",
      "     |      when :meth:`fit` is not feasible due to very large number of\n",
      "     |      `n_samples` or because X is read from a continuous stream.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The data used to compute the mean and standard deviation\n",
      "     |          used for later scaling along the features axis.\n",
      "     |\n",
      "     |      y : None\n",
      "     |          Ignored.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted scaler.\n",
      "     |\n",
      "     |  transform(self, X)\n",
      "     |      Scale features of X according to feature_range.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Input data that will be transformed.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Xt : ndarray of shape (n_samples, n_features)\n",
      "     |          Transformed data.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.OneToOneFeatureMixin:\n",
      "     |\n",
      "     |  get_feature_names_out(self, input_features=None)\n",
      "     |      Get output feature names for transformation.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      input_features : array-like of str or None, default=None\n",
      "     |          Input features.\n",
      "     |\n",
      "     |          - If `input_features` is `None`, then `feature_names_in_` is\n",
      "     |            used as feature names in. If `feature_names_in_` is not defined,\n",
      "     |            then the following input feature names are generated:\n",
      "     |            `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n",
      "     |          - If `input_features` is an array-like, then `input_features` must\n",
      "     |            match `feature_names_in_` if `feature_names_in_` is defined.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      feature_names_out : ndarray of str objects\n",
      "     |          Same as input features.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.OneToOneFeatureMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.TransformerMixin:\n",
      "     |\n",
      "     |  fit_transform(self, X, y=None, **fit_params)\n",
      "     |      Fit to data, then transform it.\n",
      "     |\n",
      "     |      Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
      "     |      and returns a transformed version of `X`.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Input samples.\n",
      "     |\n",
      "     |      y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n",
      "     |          Target values (None for unsupervised transformations).\n",
      "     |\n",
      "     |      **fit_params : dict\n",
      "     |          Additional fit parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      "     |          Transformed array.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  set_output(self, *, transform=None)\n",
      "     |      Set output container.\n",
      "     |\n",
      "     |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      "     |      for an example on how to use the API.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      transform : {\"default\", \"pandas\", \"polars\"}, default=None\n",
      "     |          Configure output of `transform` and `fit_transform`.\n",
      "     |\n",
      "     |          - `\"default\"`: Default output format of a transformer\n",
      "     |          - `\"pandas\"`: DataFrame output\n",
      "     |          - `\"polars\"`: Polars output\n",
      "     |          - `None`: Transform configuration is unchanged\n",
      "     |\n",
      "     |          .. versionadded:: 1.4\n",
      "     |              `\"polars\"` option was added.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs)\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |\n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "\n",
      "    class MultiLabelBinarizer(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "     |  MultiLabelBinarizer(*, classes=None, sparse_output=False)\n",
      "     |\n",
      "     |  Transform between iterable of iterables and a multilabel format.\n",
      "     |\n",
      "     |  Although a list of sets or tuples is a very intuitive format for multilabel\n",
      "     |  data, it is unwieldy to process. This transformer converts between this\n",
      "     |  intuitive format and the supported multilabel format: a (samples x classes)\n",
      "     |  binary matrix indicating the presence of a class label.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  classes : array-like of shape (n_classes,), default=None\n",
      "     |      Indicates an ordering for the class labels.\n",
      "     |      All entries should be unique (cannot contain duplicate classes).\n",
      "     |\n",
      "     |  sparse_output : bool, default=False\n",
      "     |      Set to True if output binary array is desired in CSR sparse format.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  classes_ : ndarray of shape (n_classes,)\n",
      "     |      A copy of the `classes` parameter when provided.\n",
      "     |      Otherwise it corresponds to the sorted set of classes found\n",
      "     |      when fitting.\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  OneHotEncoder : Encode categorical features using a one-hot aka one-of-K\n",
      "     |      scheme.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.preprocessing import MultiLabelBinarizer\n",
      "     |  >>> mlb = MultiLabelBinarizer()\n",
      "     |  >>> mlb.fit_transform([(1, 2), (3,)])\n",
      "     |  array([[1, 1, 0],\n",
      "     |         [0, 0, 1]])\n",
      "     |  >>> mlb.classes_\n",
      "     |  array([1, 2, 3])\n",
      "     |\n",
      "     |  >>> mlb.fit_transform([{'sci-fi', 'thriller'}, {'comedy'}])\n",
      "     |  array([[0, 1, 1],\n",
      "     |         [1, 0, 0]])\n",
      "     |  >>> list(mlb.classes_)\n",
      "     |  ['comedy', 'sci-fi', 'thriller']\n",
      "     |\n",
      "     |  A common mistake is to pass in a list, which leads to the following issue:\n",
      "     |\n",
      "     |  >>> mlb = MultiLabelBinarizer()\n",
      "     |  >>> mlb.fit(['sci-fi', 'thriller', 'comedy'])\n",
      "     |  MultiLabelBinarizer()\n",
      "     |  >>> mlb.classes_\n",
      "     |  array(['-', 'c', 'd', 'e', 'f', 'h', 'i', 'l', 'm', 'o', 'r', 's', 't',\n",
      "     |      'y'], dtype=object)\n",
      "     |\n",
      "     |  To correct this, the list of labels should be passed in as:\n",
      "     |\n",
      "     |  >>> mlb = MultiLabelBinarizer()\n",
      "     |  >>> mlb.fit([['sci-fi', 'thriller', 'comedy']])\n",
      "     |  MultiLabelBinarizer()\n",
      "     |  >>> mlb.classes_\n",
      "     |  array(['comedy', 'sci-fi', 'thriller'], dtype=object)\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      MultiLabelBinarizer\n",
      "     |      sklearn.base.TransformerMixin\n",
      "     |      sklearn.utils._set_output._SetOutputMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, classes=None, sparse_output=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, y)\n",
      "     |      Fit the label sets binarizer, storing :term:`classes_`.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      y : iterable of iterables\n",
      "     |          A set of labels (any orderable and hashable object) for each\n",
      "     |          sample. If the `classes` parameter is set, `y` will not be\n",
      "     |          iterated.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted estimator.\n",
      "     |\n",
      "     |  fit_transform(self, y)\n",
      "     |      Fit the label sets binarizer and transform the given label sets.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      y : iterable of iterables\n",
      "     |          A set of labels (any orderable and hashable object) for each\n",
      "     |          sample. If the `classes` parameter is set, `y` will not be\n",
      "     |          iterated.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y_indicator : {ndarray, sparse matrix} of shape (n_samples, n_classes)\n",
      "     |          A matrix such that `y_indicator[i, j] = 1` iff `classes_[j]`\n",
      "     |          is in `y[i]`, and 0 otherwise. Sparse matrix will be of CSR\n",
      "     |          format.\n",
      "     |\n",
      "     |  inverse_transform(self, yt)\n",
      "     |      Transform the given indicator matrix into label sets.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      yt : {ndarray, sparse matrix} of shape (n_samples, n_classes)\n",
      "     |          A matrix containing only 1s ands 0s.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y : list of tuples\n",
      "     |          The set of labels for each sample such that `y[i]` consists of\n",
      "     |          `classes_[j]` for each `yt[i, j] == 1`.\n",
      "     |\n",
      "     |  transform(self, y)\n",
      "     |      Transform the given label sets.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      y : iterable of iterables\n",
      "     |          A set of labels (any orderable and hashable object) for each\n",
      "     |          sample. If the `classes` parameter is set, `y` will not be\n",
      "     |          iterated.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      y_indicator : array or CSR matrix, shape (n_samples, n_classes)\n",
      "     |          A matrix such that `y_indicator[i, j] = 1` iff `classes_[j]` is in\n",
      "     |          `y[i]`, and 0 otherwise.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  set_output(self, *, transform=None)\n",
      "     |      Set output container.\n",
      "     |\n",
      "     |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      "     |      for an example on how to use the API.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      transform : {\"default\", \"pandas\", \"polars\"}, default=None\n",
      "     |          Configure output of `transform` and `fit_transform`.\n",
      "     |\n",
      "     |          - `\"default\"`: Default output format of a transformer\n",
      "     |          - `\"pandas\"`: DataFrame output\n",
      "     |          - `\"polars\"`: Polars output\n",
      "     |          - `None`: Transform configuration is unchanged\n",
      "     |\n",
      "     |          .. versionadded:: 1.4\n",
      "     |              `\"polars\"` option was added.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs)\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "\n",
      "    class Normalizer(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "     |  Normalizer(norm='l2', *, copy=True)\n",
      "     |\n",
      "     |  Normalize samples individually to unit norm.\n",
      "     |\n",
      "     |  Each sample (i.e. each row of the data matrix) with at least one\n",
      "     |  non zero component is rescaled independently of other samples so\n",
      "     |  that its norm (l1, l2 or inf) equals one.\n",
      "     |\n",
      "     |  This transformer is able to work both with dense numpy arrays and\n",
      "     |  scipy.sparse matrix (use CSR format if you want to avoid the burden of\n",
      "     |  a copy / conversion).\n",
      "     |\n",
      "     |  Scaling inputs to unit norms is a common operation for text\n",
      "     |  classification or clustering for instance. For instance the dot\n",
      "     |  product of two l2-normalized TF-IDF vectors is the cosine similarity\n",
      "     |  of the vectors and is the base similarity metric for the Vector\n",
      "     |  Space Model commonly used by the Information Retrieval community.\n",
      "     |\n",
      "     |  For an example visualization, refer to :ref:`Compare Normalizer with other\n",
      "     |  scalers <plot_all_scaling_normalizer_section>`.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <preprocessing_normalization>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  norm : {'l1', 'l2', 'max'}, default='l2'\n",
      "     |      The norm to use to normalize each non zero sample. If norm='max'\n",
      "     |      is used, values will be rescaled by the maximum of the absolute\n",
      "     |      values.\n",
      "     |\n",
      "     |  copy : bool, default=True\n",
      "     |      Set to False to perform inplace row normalization and avoid a\n",
      "     |      copy (if the input is already a numpy array or a scipy.sparse\n",
      "     |      CSR matrix).\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  normalize : Equivalent function without the estimator API.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  This estimator is :term:`stateless` and does not need to be fitted.\n",
      "     |  However, we recommend to call :meth:`fit_transform` instead of\n",
      "     |  :meth:`transform`, as parameter validation is only performed in\n",
      "     |  :meth:`fit`.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.preprocessing import Normalizer\n",
      "     |  >>> X = [[4, 1, 2, 2],\n",
      "     |  ...      [1, 3, 9, 3],\n",
      "     |  ...      [5, 7, 5, 1]]\n",
      "     |  >>> transformer = Normalizer().fit(X)  # fit does nothing.\n",
      "     |  >>> transformer\n",
      "     |  Normalizer()\n",
      "     |  >>> transformer.transform(X)\n",
      "     |  array([[0.8, 0.2, 0.4, 0.4],\n",
      "     |         [0.1, 0.3, 0.9, 0.3],\n",
      "     |         [0.5, 0.7, 0.5, 0.1]])\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      Normalizer\n",
      "     |      sklearn.base.OneToOneFeatureMixin\n",
      "     |      sklearn.base.TransformerMixin\n",
      "     |      sklearn.utils._set_output._SetOutputMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, norm='l2', *, copy=True)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y=None)\n",
      "     |      Only validates estimator's parameters.\n",
      "     |\n",
      "     |      This method allows to: (i) validate the estimator's parameters and\n",
      "     |      (ii) be consistent with the scikit-learn transformer API.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data to estimate the normalization parameters.\n",
      "     |\n",
      "     |      y : Ignored\n",
      "     |          Not used, present here for API consistency by convention.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted transformer.\n",
      "     |\n",
      "     |  set_transform_request(self: sklearn.preprocessing._data.Normalizer, *, copy: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.preprocessing._data.Normalizer from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
      "     |      Request metadata passed to the ``transform`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``transform`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``transform``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      copy : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``copy`` parameter in ``transform``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  transform(self, X, copy=None)\n",
      "     |      Scale each non zero row of X to unit norm.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data to normalize, row by row. scipy.sparse matrices should be\n",
      "     |          in CSR format to avoid an un-necessary copy.\n",
      "     |\n",
      "     |      copy : bool, default=None\n",
      "     |          Copy the input X or not.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Transformed array.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.OneToOneFeatureMixin:\n",
      "     |\n",
      "     |  get_feature_names_out(self, input_features=None)\n",
      "     |      Get output feature names for transformation.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      input_features : array-like of str or None, default=None\n",
      "     |          Input features.\n",
      "     |\n",
      "     |          - If `input_features` is `None`, then `feature_names_in_` is\n",
      "     |            used as feature names in. If `feature_names_in_` is not defined,\n",
      "     |            then the following input feature names are generated:\n",
      "     |            `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n",
      "     |          - If `input_features` is an array-like, then `input_features` must\n",
      "     |            match `feature_names_in_` if `feature_names_in_` is defined.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      feature_names_out : ndarray of str objects\n",
      "     |          Same as input features.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.OneToOneFeatureMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.TransformerMixin:\n",
      "     |\n",
      "     |  fit_transform(self, X, y=None, **fit_params)\n",
      "     |      Fit to data, then transform it.\n",
      "     |\n",
      "     |      Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
      "     |      and returns a transformed version of `X`.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Input samples.\n",
      "     |\n",
      "     |      y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n",
      "     |          Target values (None for unsupervised transformations).\n",
      "     |\n",
      "     |      **fit_params : dict\n",
      "     |          Additional fit parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      "     |          Transformed array.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  set_output(self, *, transform=None)\n",
      "     |      Set output container.\n",
      "     |\n",
      "     |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      "     |      for an example on how to use the API.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      transform : {\"default\", \"pandas\", \"polars\"}, default=None\n",
      "     |          Configure output of `transform` and `fit_transform`.\n",
      "     |\n",
      "     |          - `\"default\"`: Default output format of a transformer\n",
      "     |          - `\"pandas\"`: DataFrame output\n",
      "     |          - `\"polars\"`: Polars output\n",
      "     |          - `None`: Transform configuration is unchanged\n",
      "     |\n",
      "     |          .. versionadded:: 1.4\n",
      "     |              `\"polars\"` option was added.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs)\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |\n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "\n",
      "    class OneHotEncoder(_BaseEncoder)\n",
      "     |  OneHotEncoder(*, categories='auto', drop=None, sparse_output=True, dtype=<class 'numpy.float64'>, handle_unknown='error', min_frequency=None, max_categories=None, feature_name_combiner='concat')\n",
      "     |\n",
      "     |  Encode categorical features as a one-hot numeric array.\n",
      "     |\n",
      "     |  The input to this transformer should be an array-like of integers or\n",
      "     |  strings, denoting the values taken on by categorical (discrete) features.\n",
      "     |  The features are encoded using a one-hot (aka 'one-of-K' or 'dummy')\n",
      "     |  encoding scheme. This creates a binary column for each category and\n",
      "     |  returns a sparse matrix or dense array (depending on the ``sparse_output``\n",
      "     |  parameter).\n",
      "     |\n",
      "     |  By default, the encoder derives the categories based on the unique values\n",
      "     |  in each feature. Alternatively, you can also specify the `categories`\n",
      "     |  manually.\n",
      "     |\n",
      "     |  This encoding is needed for feeding categorical data to many scikit-learn\n",
      "     |  estimators, notably linear models and SVMs with the standard kernels.\n",
      "     |\n",
      "     |  Note: a one-hot encoding of y labels should use a LabelBinarizer\n",
      "     |  instead.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <preprocessing_categorical_features>`.\n",
      "     |  For a comparison of different encoders, refer to:\n",
      "     |  :ref:`sphx_glr_auto_examples_preprocessing_plot_target_encoder.py`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  categories : 'auto' or a list of array-like, default='auto'\n",
      "     |      Categories (unique values) per feature:\n",
      "     |\n",
      "     |      - 'auto' : Determine categories automatically from the training data.\n",
      "     |      - list : ``categories[i]`` holds the categories expected in the ith\n",
      "     |        column. The passed categories should not mix strings and numeric\n",
      "     |        values within a single feature, and should be sorted in case of\n",
      "     |        numeric values.\n",
      "     |\n",
      "     |      The used categories can be found in the ``categories_`` attribute.\n",
      "     |\n",
      "     |      .. versionadded:: 0.20\n",
      "     |\n",
      "     |  drop : {'first', 'if_binary'} or an array-like of shape (n_features,),             default=None\n",
      "     |      Specifies a methodology to use to drop one of the categories per\n",
      "     |      feature. This is useful in situations where perfectly collinear\n",
      "     |      features cause problems, such as when feeding the resulting data\n",
      "     |      into an unregularized linear regression model.\n",
      "     |\n",
      "     |      However, dropping one category breaks the symmetry of the original\n",
      "     |      representation and can therefore induce a bias in downstream models,\n",
      "     |      for instance for penalized linear classification or regression models.\n",
      "     |\n",
      "     |      - None : retain all features (the default).\n",
      "     |      - 'first' : drop the first category in each feature. If only one\n",
      "     |        category is present, the feature will be dropped entirely.\n",
      "     |      - 'if_binary' : drop the first category in each feature with two\n",
      "     |        categories. Features with 1 or more than 2 categories are\n",
      "     |        left intact.\n",
      "     |      - array : ``drop[i]`` is the category in feature ``X[:, i]`` that\n",
      "     |        should be dropped.\n",
      "     |\n",
      "     |      When `max_categories` or `min_frequency` is configured to group\n",
      "     |      infrequent categories, the dropping behavior is handled after the\n",
      "     |      grouping.\n",
      "     |\n",
      "     |      .. versionadded:: 0.21\n",
      "     |         The parameter `drop` was added in 0.21.\n",
      "     |\n",
      "     |      .. versionchanged:: 0.23\n",
      "     |         The option `drop='if_binary'` was added in 0.23.\n",
      "     |\n",
      "     |      .. versionchanged:: 1.1\n",
      "     |          Support for dropping infrequent categories.\n",
      "     |\n",
      "     |  sparse_output : bool, default=True\n",
      "     |      When ``True``, it returns a :class:`scipy.sparse.csr_matrix`,\n",
      "     |      i.e. a sparse matrix in \"Compressed Sparse Row\" (CSR) format.\n",
      "     |\n",
      "     |      .. versionadded:: 1.2\n",
      "     |         `sparse` was renamed to `sparse_output`\n",
      "     |\n",
      "     |  dtype : number type, default=np.float64\n",
      "     |      Desired dtype of output.\n",
      "     |\n",
      "     |  handle_unknown : {'error', 'ignore', 'infrequent_if_exist'},                      default='error'\n",
      "     |      Specifies the way unknown categories are handled during :meth:`transform`.\n",
      "     |\n",
      "     |      - 'error' : Raise an error if an unknown category is present during transform.\n",
      "     |      - 'ignore' : When an unknown category is encountered during\n",
      "     |        transform, the resulting one-hot encoded columns for this feature\n",
      "     |        will be all zeros. In the inverse transform, an unknown category\n",
      "     |        will be denoted as None.\n",
      "     |      - 'infrequent_if_exist' : When an unknown category is encountered\n",
      "     |        during transform, the resulting one-hot encoded columns for this\n",
      "     |        feature will map to the infrequent category if it exists. The\n",
      "     |        infrequent category will be mapped to the last position in the\n",
      "     |        encoding. During inverse transform, an unknown category will be\n",
      "     |        mapped to the category denoted `'infrequent'` if it exists. If the\n",
      "     |        `'infrequent'` category does not exist, then :meth:`transform` and\n",
      "     |        :meth:`inverse_transform` will handle an unknown category as with\n",
      "     |        `handle_unknown='ignore'`. Infrequent categories exist based on\n",
      "     |        `min_frequency` and `max_categories`. Read more in the\n",
      "     |        :ref:`User Guide <encoder_infrequent_categories>`.\n",
      "     |\n",
      "     |      .. versionchanged:: 1.1\n",
      "     |          `'infrequent_if_exist'` was added to automatically handle unknown\n",
      "     |          categories and infrequent categories.\n",
      "     |\n",
      "     |  min_frequency : int or float, default=None\n",
      "     |      Specifies the minimum frequency below which a category will be\n",
      "     |      considered infrequent.\n",
      "     |\n",
      "     |      - If `int`, categories with a smaller cardinality will be considered\n",
      "     |        infrequent.\n",
      "     |\n",
      "     |      - If `float`, categories with a smaller cardinality than\n",
      "     |        `min_frequency * n_samples`  will be considered infrequent.\n",
      "     |\n",
      "     |      .. versionadded:: 1.1\n",
      "     |          Read more in the :ref:`User Guide <encoder_infrequent_categories>`.\n",
      "     |\n",
      "     |  max_categories : int, default=None\n",
      "     |      Specifies an upper limit to the number of output features for each input\n",
      "     |      feature when considering infrequent categories. If there are infrequent\n",
      "     |      categories, `max_categories` includes the category representing the\n",
      "     |      infrequent categories along with the frequent categories. If `None`,\n",
      "     |      there is no limit to the number of output features.\n",
      "     |\n",
      "     |      .. versionadded:: 1.1\n",
      "     |          Read more in the :ref:`User Guide <encoder_infrequent_categories>`.\n",
      "     |\n",
      "     |  feature_name_combiner : \"concat\" or callable, default=\"concat\"\n",
      "     |      Callable with signature `def callable(input_feature, category)` that returns a\n",
      "     |      string. This is used to create feature names to be returned by\n",
      "     |      :meth:`get_feature_names_out`.\n",
      "     |\n",
      "     |      `\"concat\"` concatenates encoded feature name and category with\n",
      "     |      `feature + \"_\" + str(category)`.E.g. feature X with values 1, 6, 7 create\n",
      "     |      feature names `X_1, X_6, X_7`.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  categories_ : list of arrays\n",
      "     |      The categories of each feature determined during fitting\n",
      "     |      (in order of the features in X and corresponding with the output\n",
      "     |      of ``transform``). This includes the category specified in ``drop``\n",
      "     |      (if any).\n",
      "     |\n",
      "     |  drop_idx_ : array of shape (n_features,)\n",
      "     |      - ``drop_idx_[i]`` is the index in ``categories_[i]`` of the category\n",
      "     |        to be dropped for each feature.\n",
      "     |      - ``drop_idx_[i] = None`` if no category is to be dropped from the\n",
      "     |        feature with index ``i``, e.g. when `drop='if_binary'` and the\n",
      "     |        feature isn't binary.\n",
      "     |      - ``drop_idx_ = None`` if all the transformed features will be\n",
      "     |        retained.\n",
      "     |\n",
      "     |      If infrequent categories are enabled by setting `min_frequency` or\n",
      "     |      `max_categories` to a non-default value and `drop_idx[i]` corresponds\n",
      "     |      to a infrequent category, then the entire infrequent category is\n",
      "     |      dropped.\n",
      "     |\n",
      "     |      .. versionchanged:: 0.23\n",
      "     |         Added the possibility to contain `None` values.\n",
      "     |\n",
      "     |  infrequent_categories_ : list of ndarray\n",
      "     |      Defined only if infrequent categories are enabled by setting\n",
      "     |      `min_frequency` or `max_categories` to a non-default value.\n",
      "     |      `infrequent_categories_[i]` are the infrequent categories for feature\n",
      "     |      `i`. If the feature `i` has no infrequent categories\n",
      "     |      `infrequent_categories_[i]` is None.\n",
      "     |\n",
      "     |      .. versionadded:: 1.1\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  feature_name_combiner : callable or None\n",
      "     |      Callable with signature `def callable(input_feature, category)` that returns a\n",
      "     |      string. This is used to create feature names to be returned by\n",
      "     |      :meth:`get_feature_names_out`.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  OrdinalEncoder : Performs an ordinal (integer)\n",
      "     |    encoding of the categorical features.\n",
      "     |  TargetEncoder : Encodes categorical features using the target.\n",
      "     |  sklearn.feature_extraction.DictVectorizer : Performs a one-hot encoding of\n",
      "     |    dictionary items (also handles string-valued features).\n",
      "     |  sklearn.feature_extraction.FeatureHasher : Performs an approximate one-hot\n",
      "     |    encoding of dictionary items or strings.\n",
      "     |  LabelBinarizer : Binarizes labels in a one-vs-all\n",
      "     |    fashion.\n",
      "     |  MultiLabelBinarizer : Transforms between iterable of\n",
      "     |    iterables and a multilabel format, e.g. a (samples x classes) binary\n",
      "     |    matrix indicating the presence of a class label.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  Given a dataset with two features, we let the encoder find the unique\n",
      "     |  values per feature and transform the data to a binary one-hot encoding.\n",
      "     |\n",
      "     |  >>> from sklearn.preprocessing import OneHotEncoder\n",
      "     |\n",
      "     |  One can discard categories not seen during `fit`:\n",
      "     |\n",
      "     |  >>> enc = OneHotEncoder(handle_unknown='ignore')\n",
      "     |  >>> X = [['Male', 1], ['Female', 3], ['Female', 2]]\n",
      "     |  >>> enc.fit(X)\n",
      "     |  OneHotEncoder(handle_unknown='ignore')\n",
      "     |  >>> enc.categories_\n",
      "     |  [array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]\n",
      "     |  >>> enc.transform([['Female', 1], ['Male', 4]]).toarray()\n",
      "     |  array([[1., 0., 1., 0., 0.],\n",
      "     |         [0., 1., 0., 0., 0.]])\n",
      "     |  >>> enc.inverse_transform([[0, 1, 1, 0, 0], [0, 0, 0, 1, 0]])\n",
      "     |  array([['Male', 1],\n",
      "     |         [None, 2]], dtype=object)\n",
      "     |  >>> enc.get_feature_names_out(['gender', 'group'])\n",
      "     |  array(['gender_Female', 'gender_Male', 'group_1', 'group_2', 'group_3'], ...)\n",
      "     |\n",
      "     |  One can always drop the first column for each feature:\n",
      "     |\n",
      "     |  >>> drop_enc = OneHotEncoder(drop='first').fit(X)\n",
      "     |  >>> drop_enc.categories_\n",
      "     |  [array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]\n",
      "     |  >>> drop_enc.transform([['Female', 1], ['Male', 2]]).toarray()\n",
      "     |  array([[0., 0., 0.],\n",
      "     |         [1., 1., 0.]])\n",
      "     |\n",
      "     |  Or drop a column for feature only having 2 categories:\n",
      "     |\n",
      "     |  >>> drop_binary_enc = OneHotEncoder(drop='if_binary').fit(X)\n",
      "     |  >>> drop_binary_enc.transform([['Female', 1], ['Male', 2]]).toarray()\n",
      "     |  array([[0., 1., 0., 0.],\n",
      "     |         [1., 0., 1., 0.]])\n",
      "     |\n",
      "     |  One can change the way feature names are created.\n",
      "     |\n",
      "     |  >>> def custom_combiner(feature, category):\n",
      "     |  ...     return str(feature) + \"_\" + type(category).__name__ + \"_\" + str(category)\n",
      "     |  >>> custom_fnames_enc = OneHotEncoder(feature_name_combiner=custom_combiner).fit(X)\n",
      "     |  >>> custom_fnames_enc.get_feature_names_out()\n",
      "     |  array(['x0_str_Female', 'x0_str_Male', 'x1_int_1', 'x1_int_2', 'x1_int_3'],\n",
      "     |        dtype=object)\n",
      "     |\n",
      "     |  Infrequent categories are enabled by setting `max_categories` or `min_frequency`.\n",
      "     |\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> X = np.array([[\"a\"] * 5 + [\"b\"] * 20 + [\"c\"] * 10 + [\"d\"] * 3], dtype=object).T\n",
      "     |  >>> ohe = OneHotEncoder(max_categories=3, sparse_output=False).fit(X)\n",
      "     |  >>> ohe.infrequent_categories_\n",
      "     |  [array(['a', 'd'], dtype=object)]\n",
      "     |  >>> ohe.transform([[\"a\"], [\"b\"]])\n",
      "     |  array([[0., 0., 1.],\n",
      "     |         [1., 0., 0.]])\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      OneHotEncoder\n",
      "     |      _BaseEncoder\n",
      "     |      sklearn.base.TransformerMixin\n",
      "     |      sklearn.utils._set_output._SetOutputMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, categories='auto', drop=None, sparse_output=True, dtype=<class 'numpy.float64'>, handle_unknown='error', min_frequency=None, max_categories=None, feature_name_combiner='concat')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y=None)\n",
      "     |      Fit OneHotEncoder to X.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The data to determine the categories of each feature.\n",
      "     |\n",
      "     |      y : None\n",
      "     |          Ignored. This parameter exists only for compatibility with\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |          Fitted encoder.\n",
      "     |\n",
      "     |  get_feature_names_out(self, input_features=None)\n",
      "     |      Get output feature names for transformation.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      input_features : array-like of str or None, default=None\n",
      "     |          Input features.\n",
      "     |\n",
      "     |          - If `input_features` is `None`, then `feature_names_in_` is\n",
      "     |            used as feature names in. If `feature_names_in_` is not defined,\n",
      "     |            then the following input feature names are generated:\n",
      "     |            `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n",
      "     |          - If `input_features` is an array-like, then `input_features` must\n",
      "     |            match `feature_names_in_` if `feature_names_in_` is defined.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      feature_names_out : ndarray of str objects\n",
      "     |          Transformed feature names.\n",
      "     |\n",
      "     |  inverse_transform(self, X)\n",
      "     |      Convert the data back to the original representation.\n",
      "     |\n",
      "     |      When unknown categories are encountered (all zeros in the\n",
      "     |      one-hot encoding), ``None`` is used to represent this category. If the\n",
      "     |      feature with the unknown category has a dropped category, the dropped\n",
      "     |      category will be its inverse.\n",
      "     |\n",
      "     |      For a given input feature, if there is an infrequent category,\n",
      "     |      'infrequent_sklearn' will be used to represent the infrequent category.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape                 (n_samples, n_encoded_features)\n",
      "     |          The transformed data.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_tr : ndarray of shape (n_samples, n_features)\n",
      "     |          Inverse transformed array.\n",
      "     |\n",
      "     |  transform(self, X)\n",
      "     |      Transform X using one-hot encoding.\n",
      "     |\n",
      "     |      If `sparse_output=True` (default), it returns an instance of\n",
      "     |      :class:`scipy.sparse._csr.csr_matrix` (CSR format).\n",
      "     |\n",
      "     |      If there are infrequent categories for a feature, set by specifying\n",
      "     |      `max_categories` or `min_frequency`, the infrequent categories are\n",
      "     |      grouped into a single category.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The data to encode.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_out : {ndarray, sparse matrix} of shape                 (n_samples, n_encoded_features)\n",
      "     |          Transformed input. If `sparse_output=True`, a sparse matrix will be\n",
      "     |          returned.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from _BaseEncoder:\n",
      "     |\n",
      "     |  infrequent_categories_\n",
      "     |      Infrequent categories for each feature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.TransformerMixin:\n",
      "     |\n",
      "     |  fit_transform(self, X, y=None, **fit_params)\n",
      "     |      Fit to data, then transform it.\n",
      "     |\n",
      "     |      Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
      "     |      and returns a transformed version of `X`.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Input samples.\n",
      "     |\n",
      "     |      y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n",
      "     |          Target values (None for unsupervised transformations).\n",
      "     |\n",
      "     |      **fit_params : dict\n",
      "     |          Additional fit parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      "     |          Transformed array.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  set_output(self, *, transform=None)\n",
      "     |      Set output container.\n",
      "     |\n",
      "     |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      "     |      for an example on how to use the API.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      transform : {\"default\", \"pandas\", \"polars\"}, default=None\n",
      "     |          Configure output of `transform` and `fit_transform`.\n",
      "     |\n",
      "     |          - `\"default\"`: Default output format of a transformer\n",
      "     |          - `\"pandas\"`: DataFrame output\n",
      "     |          - `\"polars\"`: Polars output\n",
      "     |          - `None`: Transform configuration is unchanged\n",
      "     |\n",
      "     |          .. versionadded:: 1.4\n",
      "     |              `\"polars\"` option was added.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs)\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "\n",
      "    class OrdinalEncoder(sklearn.base.OneToOneFeatureMixin, _BaseEncoder)\n",
      "     |  OrdinalEncoder(*, categories='auto', dtype=<class 'numpy.float64'>, handle_unknown='error', unknown_value=None, encoded_missing_value=nan, min_frequency=None, max_categories=None)\n",
      "     |\n",
      "     |  Encode categorical features as an integer array.\n",
      "     |\n",
      "     |  The input to this transformer should be an array-like of integers or\n",
      "     |  strings, denoting the values taken on by categorical (discrete) features.\n",
      "     |  The features are converted to ordinal integers. This results in\n",
      "     |  a single column of integers (0 to n_categories - 1) per feature.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <preprocessing_categorical_features>`.\n",
      "     |  For a comparison of different encoders, refer to:\n",
      "     |  :ref:`sphx_glr_auto_examples_preprocessing_plot_target_encoder.py`.\n",
      "     |\n",
      "     |  .. versionadded:: 0.20\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  categories : 'auto' or a list of array-like, default='auto'\n",
      "     |      Categories (unique values) per feature:\n",
      "     |\n",
      "     |      - 'auto' : Determine categories automatically from the training data.\n",
      "     |      - list : ``categories[i]`` holds the categories expected in the ith\n",
      "     |        column. The passed categories should not mix strings and numeric\n",
      "     |        values, and should be sorted in case of numeric values.\n",
      "     |\n",
      "     |      The used categories can be found in the ``categories_`` attribute.\n",
      "     |\n",
      "     |  dtype : number type, default=np.float64\n",
      "     |      Desired dtype of output.\n",
      "     |\n",
      "     |  handle_unknown : {'error', 'use_encoded_value'}, default='error'\n",
      "     |      When set to 'error' an error will be raised in case an unknown\n",
      "     |      categorical feature is present during transform. When set to\n",
      "     |      'use_encoded_value', the encoded value of unknown categories will be\n",
      "     |      set to the value given for the parameter `unknown_value`. In\n",
      "     |      :meth:`inverse_transform`, an unknown category will be denoted as None.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  unknown_value : int or np.nan, default=None\n",
      "     |      When the parameter handle_unknown is set to 'use_encoded_value', this\n",
      "     |      parameter is required and will set the encoded value of unknown\n",
      "     |      categories. It has to be distinct from the values used to encode any of\n",
      "     |      the categories in `fit`. If set to np.nan, the `dtype` parameter must\n",
      "     |      be a float dtype.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  encoded_missing_value : int or np.nan, default=np.nan\n",
      "     |      Encoded value of missing categories. If set to `np.nan`, then the `dtype`\n",
      "     |      parameter must be a float dtype.\n",
      "     |\n",
      "     |      .. versionadded:: 1.1\n",
      "     |\n",
      "     |  min_frequency : int or float, default=None\n",
      "     |      Specifies the minimum frequency below which a category will be\n",
      "     |      considered infrequent.\n",
      "     |\n",
      "     |      - If `int`, categories with a smaller cardinality will be considered\n",
      "     |        infrequent.\n",
      "     |\n",
      "     |      - If `float`, categories with a smaller cardinality than\n",
      "     |        `min_frequency * n_samples`  will be considered infrequent.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |          Read more in the :ref:`User Guide <encoder_infrequent_categories>`.\n",
      "     |\n",
      "     |  max_categories : int, default=None\n",
      "     |      Specifies an upper limit to the number of output categories for each input\n",
      "     |      feature when considering infrequent categories. If there are infrequent\n",
      "     |      categories, `max_categories` includes the category representing the\n",
      "     |      infrequent categories along with the frequent categories. If `None`,\n",
      "     |      there is no limit to the number of output features.\n",
      "     |\n",
      "     |      `max_categories` do **not** take into account missing or unknown\n",
      "     |      categories. Setting `unknown_value` or `encoded_missing_value` to an\n",
      "     |      integer will increase the number of unique integer codes by one each.\n",
      "     |      This can result in up to `max_categories + 2` integer codes.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |          Read more in the :ref:`User Guide <encoder_infrequent_categories>`.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  categories_ : list of arrays\n",
      "     |      The categories of each feature determined during ``fit`` (in order of\n",
      "     |      the features in X and corresponding with the output of ``transform``).\n",
      "     |      This does not include categories that weren't seen during ``fit``.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  infrequent_categories_ : list of ndarray\n",
      "     |      Defined only if infrequent categories are enabled by setting\n",
      "     |      `min_frequency` or `max_categories` to a non-default value.\n",
      "     |      `infrequent_categories_[i]` are the infrequent categories for feature\n",
      "     |      `i`. If the feature `i` has no infrequent categories\n",
      "     |      `infrequent_categories_[i]` is None.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  OneHotEncoder : Performs a one-hot encoding of categorical features. This encoding\n",
      "     |      is suitable for low to medium cardinality categorical variables, both in\n",
      "     |      supervised and unsupervised settings.\n",
      "     |  TargetEncoder : Encodes categorical features using supervised signal\n",
      "     |      in a classification or regression pipeline. This encoding is typically\n",
      "     |      suitable for high cardinality categorical variables.\n",
      "     |  LabelEncoder : Encodes target labels with values between 0 and\n",
      "     |      ``n_classes-1``.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  With a high proportion of `nan` values, inferring categories becomes slow with\n",
      "     |  Python versions before 3.10. The handling of `nan` values was improved\n",
      "     |  from Python 3.10 onwards, (c.f.\n",
      "     |  `bpo-43475 <https://github.com/python/cpython/issues/87641>`_).\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  Given a dataset with two features, we let the encoder find the unique\n",
      "     |  values per feature and transform the data to an ordinal encoding.\n",
      "     |\n",
      "     |  >>> from sklearn.preprocessing import OrdinalEncoder\n",
      "     |  >>> enc = OrdinalEncoder()\n",
      "     |  >>> X = [['Male', 1], ['Female', 3], ['Female', 2]]\n",
      "     |  >>> enc.fit(X)\n",
      "     |  OrdinalEncoder()\n",
      "     |  >>> enc.categories_\n",
      "     |  [array(['Female', 'Male'], dtype=object), array([1, 2, 3], dtype=object)]\n",
      "     |  >>> enc.transform([['Female', 3], ['Male', 1]])\n",
      "     |  array([[0., 2.],\n",
      "     |         [1., 0.]])\n",
      "     |\n",
      "     |  >>> enc.inverse_transform([[1, 0], [0, 1]])\n",
      "     |  array([['Male', 1],\n",
      "     |         ['Female', 2]], dtype=object)\n",
      "     |\n",
      "     |  By default, :class:`OrdinalEncoder` is lenient towards missing values by\n",
      "     |  propagating them.\n",
      "     |\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> X = [['Male', 1], ['Female', 3], ['Female', np.nan]]\n",
      "     |  >>> enc.fit_transform(X)\n",
      "     |  array([[ 1.,  0.],\n",
      "     |         [ 0.,  1.],\n",
      "     |         [ 0., nan]])\n",
      "     |\n",
      "     |  You can use the parameter `encoded_missing_value` to encode missing values.\n",
      "     |\n",
      "     |  >>> enc.set_params(encoded_missing_value=-1).fit_transform(X)\n",
      "     |  array([[ 1.,  0.],\n",
      "     |         [ 0.,  1.],\n",
      "     |         [ 0., -1.]])\n",
      "     |\n",
      "     |  Infrequent categories are enabled by setting `max_categories` or `min_frequency`.\n",
      "     |  In the following example, \"a\" and \"d\" are considered infrequent and grouped\n",
      "     |  together into a single category, \"b\" and \"c\" are their own categories, unknown\n",
      "     |  values are encoded as 3 and missing values are encoded as 4.\n",
      "     |\n",
      "     |  >>> X_train = np.array(\n",
      "     |  ...     [[\"a\"] * 5 + [\"b\"] * 20 + [\"c\"] * 10 + [\"d\"] * 3 + [np.nan]],\n",
      "     |  ...     dtype=object).T\n",
      "     |  >>> enc = OrdinalEncoder(\n",
      "     |  ...     handle_unknown=\"use_encoded_value\", unknown_value=3,\n",
      "     |  ...     max_categories=3, encoded_missing_value=4)\n",
      "     |  >>> _ = enc.fit(X_train)\n",
      "     |  >>> X_test = np.array([[\"a\"], [\"b\"], [\"c\"], [\"d\"], [\"e\"], [np.nan]], dtype=object)\n",
      "     |  >>> enc.transform(X_test)\n",
      "     |  array([[2.],\n",
      "     |         [0.],\n",
      "     |         [1.],\n",
      "     |         [2.],\n",
      "     |         [3.],\n",
      "     |         [4.]])\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      OrdinalEncoder\n",
      "     |      sklearn.base.OneToOneFeatureMixin\n",
      "     |      _BaseEncoder\n",
      "     |      sklearn.base.TransformerMixin\n",
      "     |      sklearn.utils._set_output._SetOutputMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, categories='auto', dtype=<class 'numpy.float64'>, handle_unknown='error', unknown_value=None, encoded_missing_value=nan, min_frequency=None, max_categories=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y=None)\n",
      "     |      Fit the OrdinalEncoder to X.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The data to determine the categories of each feature.\n",
      "     |\n",
      "     |      y : None\n",
      "     |          Ignored. This parameter exists only for compatibility with\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted encoder.\n",
      "     |\n",
      "     |  inverse_transform(self, X)\n",
      "     |      Convert the data back to the original representation.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_encoded_features)\n",
      "     |          The transformed data.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_tr : ndarray of shape (n_samples, n_features)\n",
      "     |          Inverse transformed array.\n",
      "     |\n",
      "     |  transform(self, X)\n",
      "     |      Transform X to ordinal codes.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The data to encode.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_out : ndarray of shape (n_samples, n_features)\n",
      "     |          Transformed input.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.OneToOneFeatureMixin:\n",
      "     |\n",
      "     |  get_feature_names_out(self, input_features=None)\n",
      "     |      Get output feature names for transformation.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      input_features : array-like of str or None, default=None\n",
      "     |          Input features.\n",
      "     |\n",
      "     |          - If `input_features` is `None`, then `feature_names_in_` is\n",
      "     |            used as feature names in. If `feature_names_in_` is not defined,\n",
      "     |            then the following input feature names are generated:\n",
      "     |            `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n",
      "     |          - If `input_features` is an array-like, then `input_features` must\n",
      "     |            match `feature_names_in_` if `feature_names_in_` is defined.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      feature_names_out : ndarray of str objects\n",
      "     |          Same as input features.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.OneToOneFeatureMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from _BaseEncoder:\n",
      "     |\n",
      "     |  infrequent_categories_\n",
      "     |      Infrequent categories for each feature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.TransformerMixin:\n",
      "     |\n",
      "     |  fit_transform(self, X, y=None, **fit_params)\n",
      "     |      Fit to data, then transform it.\n",
      "     |\n",
      "     |      Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
      "     |      and returns a transformed version of `X`.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Input samples.\n",
      "     |\n",
      "     |      y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n",
      "     |          Target values (None for unsupervised transformations).\n",
      "     |\n",
      "     |      **fit_params : dict\n",
      "     |          Additional fit parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      "     |          Transformed array.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  set_output(self, *, transform=None)\n",
      "     |      Set output container.\n",
      "     |\n",
      "     |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      "     |      for an example on how to use the API.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      transform : {\"default\", \"pandas\", \"polars\"}, default=None\n",
      "     |          Configure output of `transform` and `fit_transform`.\n",
      "     |\n",
      "     |          - `\"default\"`: Default output format of a transformer\n",
      "     |          - `\"pandas\"`: DataFrame output\n",
      "     |          - `\"polars\"`: Polars output\n",
      "     |          - `None`: Transform configuration is unchanged\n",
      "     |\n",
      "     |          .. versionadded:: 1.4\n",
      "     |              `\"polars\"` option was added.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs)\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |\n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "\n",
      "    class PolynomialFeatures(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "     |  PolynomialFeatures(degree=2, *, interaction_only=False, include_bias=True, order='C')\n",
      "     |\n",
      "     |  Generate polynomial and interaction features.\n",
      "     |\n",
      "     |  Generate a new feature matrix consisting of all polynomial combinations\n",
      "     |  of the features with degree less than or equal to the specified degree.\n",
      "     |  For example, if an input sample is two dimensional and of the form\n",
      "     |  [a, b], the degree-2 polynomial features are [1, a, b, a^2, ab, b^2].\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <polynomial_features>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  degree : int or tuple (min_degree, max_degree), default=2\n",
      "     |      If a single int is given, it specifies the maximal degree of the\n",
      "     |      polynomial features. If a tuple `(min_degree, max_degree)` is passed,\n",
      "     |      then `min_degree` is the minimum and `max_degree` is the maximum\n",
      "     |      polynomial degree of the generated features. Note that `min_degree=0`\n",
      "     |      and `min_degree=1` are equivalent as outputting the degree zero term is\n",
      "     |      determined by `include_bias`.\n",
      "     |\n",
      "     |  interaction_only : bool, default=False\n",
      "     |      If `True`, only interaction features are produced: features that are\n",
      "     |      products of at most `degree` *distinct* input features, i.e. terms with\n",
      "     |      power of 2 or higher of the same input feature are excluded:\n",
      "     |\n",
      "     |          - included: `x[0]`, `x[1]`, `x[0] * x[1]`, etc.\n",
      "     |          - excluded: `x[0] ** 2`, `x[0] ** 2 * x[1]`, etc.\n",
      "     |\n",
      "     |  include_bias : bool, default=True\n",
      "     |      If `True` (default), then include a bias column, the feature in which\n",
      "     |      all polynomial powers are zero (i.e. a column of ones - acts as an\n",
      "     |      intercept term in a linear model).\n",
      "     |\n",
      "     |  order : {'C', 'F'}, default='C'\n",
      "     |      Order of output array in the dense case. `'F'` order is faster to\n",
      "     |      compute, but may slow down subsequent estimators.\n",
      "     |\n",
      "     |      .. versionadded:: 0.21\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  powers_ : ndarray of shape (`n_output_features_`, `n_features_in_`)\n",
      "     |      `powers_[i, j]` is the exponent of the jth input in the ith output.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  n_output_features_ : int\n",
      "     |      The total number of polynomial output features. The number of output\n",
      "     |      features is computed by iterating over all suitably sized combinations\n",
      "     |      of input features.\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  SplineTransformer : Transformer that generates univariate B-spline bases\n",
      "     |      for features.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  Be aware that the number of features in the output array scales\n",
      "     |  polynomially in the number of features of the input array, and\n",
      "     |  exponentially in the degree. High degrees can cause overfitting.\n",
      "     |\n",
      "     |  See :ref:`examples/linear_model/plot_polynomial_interpolation.py\n",
      "     |  <sphx_glr_auto_examples_linear_model_plot_polynomial_interpolation.py>`\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.preprocessing import PolynomialFeatures\n",
      "     |  >>> X = np.arange(6).reshape(3, 2)\n",
      "     |  >>> X\n",
      "     |  array([[0, 1],\n",
      "     |         [2, 3],\n",
      "     |         [4, 5]])\n",
      "     |  >>> poly = PolynomialFeatures(2)\n",
      "     |  >>> poly.fit_transform(X)\n",
      "     |  array([[ 1.,  0.,  1.,  0.,  0.,  1.],\n",
      "     |         [ 1.,  2.,  3.,  4.,  6.,  9.],\n",
      "     |         [ 1.,  4.,  5., 16., 20., 25.]])\n",
      "     |  >>> poly = PolynomialFeatures(interaction_only=True)\n",
      "     |  >>> poly.fit_transform(X)\n",
      "     |  array([[ 1.,  0.,  1.,  0.],\n",
      "     |         [ 1.,  2.,  3.,  6.],\n",
      "     |         [ 1.,  4.,  5., 20.]])\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      PolynomialFeatures\n",
      "     |      sklearn.base.TransformerMixin\n",
      "     |      sklearn.utils._set_output._SetOutputMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, degree=2, *, interaction_only=False, include_bias=True, order='C')\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y=None)\n",
      "     |      Compute number of output features.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data.\n",
      "     |\n",
      "     |      y : Ignored\n",
      "     |          Not used, present here for API consistency by convention.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted transformer.\n",
      "     |\n",
      "     |  get_feature_names_out(self, input_features=None)\n",
      "     |      Get output feature names for transformation.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      input_features : array-like of str or None, default=None\n",
      "     |          Input features.\n",
      "     |\n",
      "     |          - If `input_features is None`, then `feature_names_in_` is\n",
      "     |            used as feature names in. If `feature_names_in_` is not defined,\n",
      "     |            then the following input feature names are generated:\n",
      "     |            `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n",
      "     |          - If `input_features` is an array-like, then `input_features` must\n",
      "     |            match `feature_names_in_` if `feature_names_in_` is defined.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      feature_names_out : ndarray of str objects\n",
      "     |          Transformed feature names.\n",
      "     |\n",
      "     |  transform(self, X)\n",
      "     |      Transform data to polynomial features.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data to transform, row by row.\n",
      "     |\n",
      "     |          Prefer CSR over CSC for sparse input (for speed), but CSC is\n",
      "     |          required if the degree is 4 or higher. If the degree is less than\n",
      "     |          4 and the input format is CSC, it will be converted to CSR, have\n",
      "     |          its polynomial features generated, then converted back to CSC.\n",
      "     |\n",
      "     |          If the degree is 2 or 3, the method described in \"Leveraging\n",
      "     |          Sparsity to Speed Up Polynomial Feature Expansions of CSR Matrices\n",
      "     |          Using K-Simplex Numbers\" by Andrew Nystrom and John Hughes is\n",
      "     |          used, which is much faster than the method used on CSC input. For\n",
      "     |          this reason, a CSC input will be converted to CSR, and the output\n",
      "     |          will be converted back to CSC prior to being returned, hence the\n",
      "     |          preference of CSR.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      XP : {ndarray, sparse matrix} of shape (n_samples, NP)\n",
      "     |          The matrix of features, where `NP` is the number of polynomial\n",
      "     |          features generated from the combination of inputs. If a sparse\n",
      "     |          matrix is provided, it will be converted into a sparse\n",
      "     |          `csr_matrix`.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |\n",
      "     |  powers_\n",
      "     |      Exponent for each of the inputs in the output.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.TransformerMixin:\n",
      "     |\n",
      "     |  fit_transform(self, X, y=None, **fit_params)\n",
      "     |      Fit to data, then transform it.\n",
      "     |\n",
      "     |      Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
      "     |      and returns a transformed version of `X`.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Input samples.\n",
      "     |\n",
      "     |      y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n",
      "     |          Target values (None for unsupervised transformations).\n",
      "     |\n",
      "     |      **fit_params : dict\n",
      "     |          Additional fit parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      "     |          Transformed array.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  set_output(self, *, transform=None)\n",
      "     |      Set output container.\n",
      "     |\n",
      "     |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      "     |      for an example on how to use the API.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      transform : {\"default\", \"pandas\", \"polars\"}, default=None\n",
      "     |          Configure output of `transform` and `fit_transform`.\n",
      "     |\n",
      "     |          - `\"default\"`: Default output format of a transformer\n",
      "     |          - `\"pandas\"`: DataFrame output\n",
      "     |          - `\"polars\"`: Polars output\n",
      "     |          - `None`: Transform configuration is unchanged\n",
      "     |\n",
      "     |          .. versionadded:: 1.4\n",
      "     |              `\"polars\"` option was added.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs)\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "\n",
      "    class PowerTransformer(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "     |  PowerTransformer(method='yeo-johnson', *, standardize=True, copy=True)\n",
      "     |\n",
      "     |  Apply a power transform featurewise to make data more Gaussian-like.\n",
      "     |\n",
      "     |  Power transforms are a family of parametric, monotonic transformations\n",
      "     |  that are applied to make data more Gaussian-like. This is useful for\n",
      "     |  modeling issues related to heteroscedasticity (non-constant variance),\n",
      "     |  or other situations where normality is desired.\n",
      "     |\n",
      "     |  Currently, PowerTransformer supports the Box-Cox transform and the\n",
      "     |  Yeo-Johnson transform. The optimal parameter for stabilizing variance and\n",
      "     |  minimizing skewness is estimated through maximum likelihood.\n",
      "     |\n",
      "     |  Box-Cox requires input data to be strictly positive, while Yeo-Johnson\n",
      "     |  supports both positive or negative data.\n",
      "     |\n",
      "     |  By default, zero-mean, unit-variance normalization is applied to the\n",
      "     |  transformed data.\n",
      "     |\n",
      "     |  For an example visualization, refer to :ref:`Compare PowerTransformer with\n",
      "     |  other scalers <plot_all_scaling_power_transformer_section>`. To see the\n",
      "     |  effect of Box-Cox and Yeo-Johnson transformations on different\n",
      "     |  distributions, see:\n",
      "     |  :ref:`sphx_glr_auto_examples_preprocessing_plot_map_data_to_normal.py`.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <preprocessing_transformer>`.\n",
      "     |\n",
      "     |  .. versionadded:: 0.20\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  method : {'yeo-johnson', 'box-cox'}, default='yeo-johnson'\n",
      "     |      The power transform method. Available methods are:\n",
      "     |\n",
      "     |      - 'yeo-johnson' [1]_, works with positive and negative values\n",
      "     |      - 'box-cox' [2]_, only works with strictly positive values\n",
      "     |\n",
      "     |  standardize : bool, default=True\n",
      "     |      Set to True to apply zero-mean, unit-variance normalization to the\n",
      "     |      transformed output.\n",
      "     |\n",
      "     |  copy : bool, default=True\n",
      "     |      Set to False to perform inplace computation during transformation.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  lambdas_ : ndarray of float of shape (n_features,)\n",
      "     |      The parameters of the power transformation for the selected features.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  power_transform : Equivalent function without the estimator API.\n",
      "     |\n",
      "     |  QuantileTransformer : Maps data to a standard normal distribution with\n",
      "     |      the parameter `output_distribution='normal'`.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  NaNs are treated as missing values: disregarded in ``fit``, and maintained\n",
      "     |  in ``transform``.\n",
      "     |\n",
      "     |  References\n",
      "     |  ----------\n",
      "     |\n",
      "     |  .. [1] :doi:`I.K. Yeo and R.A. Johnson, \"A new family of power\n",
      "     |         transformations to improve normality or symmetry.\" Biometrika,\n",
      "     |         87(4), pp.954-959, (2000). <10.1093/biomet/87.4.954>`\n",
      "     |\n",
      "     |  .. [2] :doi:`G.E.P. Box and D.R. Cox, \"An Analysis of Transformations\",\n",
      "     |         Journal of the Royal Statistical Society B, 26, 211-252 (1964).\n",
      "     |         <10.1111/j.2517-6161.1964.tb00553.x>`\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.preprocessing import PowerTransformer\n",
      "     |  >>> pt = PowerTransformer()\n",
      "     |  >>> data = [[1, 2], [3, 2], [4, 5]]\n",
      "     |  >>> print(pt.fit(data))\n",
      "     |  PowerTransformer()\n",
      "     |  >>> print(pt.lambdas_)\n",
      "     |  [ 1.386... -3.100...]\n",
      "     |  >>> print(pt.transform(data))\n",
      "     |  [[-1.316... -0.707...]\n",
      "     |   [ 0.209... -0.707...]\n",
      "     |   [ 1.106...  1.414...]]\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      PowerTransformer\n",
      "     |      sklearn.base.OneToOneFeatureMixin\n",
      "     |      sklearn.base.TransformerMixin\n",
      "     |      sklearn.utils._set_output._SetOutputMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, method='yeo-johnson', *, standardize=True, copy=True)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y=None)\n",
      "     |      Estimate the optimal parameter lambda for each feature.\n",
      "     |\n",
      "     |      The optimal lambda parameter for minimizing skewness is estimated on\n",
      "     |      each feature independently using maximum likelihood.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The data used to estimate the optimal transformation parameters.\n",
      "     |\n",
      "     |      y : None\n",
      "     |          Ignored.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted transformer.\n",
      "     |\n",
      "     |  fit_transform(self, X, y=None)\n",
      "     |      Fit `PowerTransformer` to `X`, then transform `X`.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The data used to estimate the optimal transformation parameters\n",
      "     |          and to be transformed using a power transformation.\n",
      "     |\n",
      "     |      y : Ignored\n",
      "     |          Not used, present for API consistency by convention.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_new : ndarray of shape (n_samples, n_features)\n",
      "     |          Transformed data.\n",
      "     |\n",
      "     |  inverse_transform(self, X)\n",
      "     |      Apply the inverse power transformation using the fitted lambdas.\n",
      "     |\n",
      "     |      The inverse of the Box-Cox transformation is given by::\n",
      "     |\n",
      "     |          if lambda_ == 0:\n",
      "     |              X = exp(X_trans)\n",
      "     |          else:\n",
      "     |              X = (X_trans * lambda_ + 1) ** (1 / lambda_)\n",
      "     |\n",
      "     |      The inverse of the Yeo-Johnson transformation is given by::\n",
      "     |\n",
      "     |          if X >= 0 and lambda_ == 0:\n",
      "     |              X = exp(X_trans) - 1\n",
      "     |          elif X >= 0 and lambda_ != 0:\n",
      "     |              X = (X_trans * lambda_ + 1) ** (1 / lambda_) - 1\n",
      "     |          elif X < 0 and lambda_ != 2:\n",
      "     |              X = 1 - (-(2 - lambda_) * X_trans + 1) ** (1 / (2 - lambda_))\n",
      "     |          elif X < 0 and lambda_ == 2:\n",
      "     |              X = 1 - exp(-X_trans)\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The transformed data.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X : ndarray of shape (n_samples, n_features)\n",
      "     |          The original data.\n",
      "     |\n",
      "     |  transform(self, X)\n",
      "     |      Apply the power transform to each feature using the fitted lambdas.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The data to be transformed using a power transformation.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_trans : ndarray of shape (n_samples, n_features)\n",
      "     |          The transformed data.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.OneToOneFeatureMixin:\n",
      "     |\n",
      "     |  get_feature_names_out(self, input_features=None)\n",
      "     |      Get output feature names for transformation.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      input_features : array-like of str or None, default=None\n",
      "     |          Input features.\n",
      "     |\n",
      "     |          - If `input_features` is `None`, then `feature_names_in_` is\n",
      "     |            used as feature names in. If `feature_names_in_` is not defined,\n",
      "     |            then the following input feature names are generated:\n",
      "     |            `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n",
      "     |          - If `input_features` is an array-like, then `input_features` must\n",
      "     |            match `feature_names_in_` if `feature_names_in_` is defined.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      feature_names_out : ndarray of str objects\n",
      "     |          Same as input features.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.OneToOneFeatureMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  set_output(self, *, transform=None)\n",
      "     |      Set output container.\n",
      "     |\n",
      "     |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      "     |      for an example on how to use the API.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      transform : {\"default\", \"pandas\", \"polars\"}, default=None\n",
      "     |          Configure output of `transform` and `fit_transform`.\n",
      "     |\n",
      "     |          - `\"default\"`: Default output format of a transformer\n",
      "     |          - `\"pandas\"`: DataFrame output\n",
      "     |          - `\"polars\"`: Polars output\n",
      "     |          - `None`: Transform configuration is unchanged\n",
      "     |\n",
      "     |          .. versionadded:: 1.4\n",
      "     |              `\"polars\"` option was added.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs)\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |\n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "\n",
      "    class QuantileTransformer(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "     |  QuantileTransformer(*, n_quantiles=1000, output_distribution='uniform', ignore_implicit_zeros=False, subsample=10000, random_state=None, copy=True)\n",
      "     |\n",
      "     |  Transform features using quantiles information.\n",
      "     |\n",
      "     |  This method transforms the features to follow a uniform or a normal\n",
      "     |  distribution. Therefore, for a given feature, this transformation tends\n",
      "     |  to spread out the most frequent values. It also reduces the impact of\n",
      "     |  (marginal) outliers: this is therefore a robust preprocessing scheme.\n",
      "     |\n",
      "     |  The transformation is applied on each feature independently. First an\n",
      "     |  estimate of the cumulative distribution function of a feature is\n",
      "     |  used to map the original values to a uniform distribution. The obtained\n",
      "     |  values are then mapped to the desired output distribution using the\n",
      "     |  associated quantile function. Features values of new/unseen data that fall\n",
      "     |  below or above the fitted range will be mapped to the bounds of the output\n",
      "     |  distribution. Note that this transform is non-linear. It may distort linear\n",
      "     |  correlations between variables measured at the same scale but renders\n",
      "     |  variables measured at different scales more directly comparable.\n",
      "     |\n",
      "     |  For example visualizations, refer to :ref:`Compare QuantileTransformer with\n",
      "     |  other scalers <plot_all_scaling_quantile_transformer_section>`.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <preprocessing_transformer>`.\n",
      "     |\n",
      "     |  .. versionadded:: 0.19\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  n_quantiles : int, default=1000 or n_samples\n",
      "     |      Number of quantiles to be computed. It corresponds to the number\n",
      "     |      of landmarks used to discretize the cumulative distribution function.\n",
      "     |      If n_quantiles is larger than the number of samples, n_quantiles is set\n",
      "     |      to the number of samples as a larger number of quantiles does not give\n",
      "     |      a better approximation of the cumulative distribution function\n",
      "     |      estimator.\n",
      "     |\n",
      "     |  output_distribution : {'uniform', 'normal'}, default='uniform'\n",
      "     |      Marginal distribution for the transformed data. The choices are\n",
      "     |      'uniform' (default) or 'normal'.\n",
      "     |\n",
      "     |  ignore_implicit_zeros : bool, default=False\n",
      "     |      Only applies to sparse matrices. If True, the sparse entries of the\n",
      "     |      matrix are discarded to compute the quantile statistics. If False,\n",
      "     |      these entries are treated as zeros.\n",
      "     |\n",
      "     |  subsample : int or None, default=10_000\n",
      "     |      Maximum number of samples used to estimate the quantiles for\n",
      "     |      computational efficiency. Note that the subsampling procedure may\n",
      "     |      differ for value-identical sparse and dense matrices.\n",
      "     |      Disable subsampling by setting `subsample=None`.\n",
      "     |\n",
      "     |      .. versionadded:: 1.5\n",
      "     |         The option `None` to disable subsampling was added.\n",
      "     |\n",
      "     |  random_state : int, RandomState instance or None, default=None\n",
      "     |      Determines random number generation for subsampling and smoothing\n",
      "     |      noise.\n",
      "     |      Please see ``subsample`` for more details.\n",
      "     |      Pass an int for reproducible results across multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |\n",
      "     |  copy : bool, default=True\n",
      "     |      Set to False to perform inplace transformation and avoid a copy (if the\n",
      "     |      input is already a numpy array).\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  n_quantiles_ : int\n",
      "     |      The actual number of quantiles used to discretize the cumulative\n",
      "     |      distribution function.\n",
      "     |\n",
      "     |  quantiles_ : ndarray of shape (n_quantiles, n_features)\n",
      "     |      The values corresponding the quantiles of reference.\n",
      "     |\n",
      "     |  references_ : ndarray of shape (n_quantiles, )\n",
      "     |      Quantiles of references.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  quantile_transform : Equivalent function without the estimator API.\n",
      "     |  PowerTransformer : Perform mapping to a normal distribution using a power\n",
      "     |      transform.\n",
      "     |  StandardScaler : Perform standardization that is faster, but less robust\n",
      "     |      to outliers.\n",
      "     |  RobustScaler : Perform robust standardization that removes the influence\n",
      "     |      of outliers but does not put outliers and inliers on the same scale.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  NaNs are treated as missing values: disregarded in fit, and maintained in\n",
      "     |  transform.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.preprocessing import QuantileTransformer\n",
      "     |  >>> rng = np.random.RandomState(0)\n",
      "     |  >>> X = np.sort(rng.normal(loc=0.5, scale=0.25, size=(25, 1)), axis=0)\n",
      "     |  >>> qt = QuantileTransformer(n_quantiles=10, random_state=0)\n",
      "     |  >>> qt.fit_transform(X)\n",
      "     |  array([...])\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      QuantileTransformer\n",
      "     |      sklearn.base.OneToOneFeatureMixin\n",
      "     |      sklearn.base.TransformerMixin\n",
      "     |      sklearn.utils._set_output._SetOutputMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, n_quantiles=1000, output_distribution='uniform', ignore_implicit_zeros=False, subsample=10000, random_state=None, copy=True)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y=None)\n",
      "     |      Compute the quantiles used for transforming.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data used to scale along the features axis. If a sparse\n",
      "     |          matrix is provided, it will be converted into a sparse\n",
      "     |          ``csc_matrix``. Additionally, the sparse matrix needs to be\n",
      "     |          nonnegative if `ignore_implicit_zeros` is False.\n",
      "     |\n",
      "     |      y : None\n",
      "     |          Ignored.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |         Fitted transformer.\n",
      "     |\n",
      "     |  inverse_transform(self, X)\n",
      "     |      Back-projection to the original space.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data used to scale along the features axis. If a sparse\n",
      "     |          matrix is provided, it will be converted into a sparse\n",
      "     |          ``csc_matrix``. Additionally, the sparse matrix needs to be\n",
      "     |          nonnegative if `ignore_implicit_zeros` is False.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Xt : {ndarray, sparse matrix} of (n_samples, n_features)\n",
      "     |          The projected data.\n",
      "     |\n",
      "     |  transform(self, X)\n",
      "     |      Feature-wise transformation of the data.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data used to scale along the features axis. If a sparse\n",
      "     |          matrix is provided, it will be converted into a sparse\n",
      "     |          ``csc_matrix``. Additionally, the sparse matrix needs to be\n",
      "     |          nonnegative if `ignore_implicit_zeros` is False.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Xt : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The projected data.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.OneToOneFeatureMixin:\n",
      "     |\n",
      "     |  get_feature_names_out(self, input_features=None)\n",
      "     |      Get output feature names for transformation.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      input_features : array-like of str or None, default=None\n",
      "     |          Input features.\n",
      "     |\n",
      "     |          - If `input_features` is `None`, then `feature_names_in_` is\n",
      "     |            used as feature names in. If `feature_names_in_` is not defined,\n",
      "     |            then the following input feature names are generated:\n",
      "     |            `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n",
      "     |          - If `input_features` is an array-like, then `input_features` must\n",
      "     |            match `feature_names_in_` if `feature_names_in_` is defined.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      feature_names_out : ndarray of str objects\n",
      "     |          Same as input features.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.OneToOneFeatureMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.TransformerMixin:\n",
      "     |\n",
      "     |  fit_transform(self, X, y=None, **fit_params)\n",
      "     |      Fit to data, then transform it.\n",
      "     |\n",
      "     |      Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
      "     |      and returns a transformed version of `X`.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Input samples.\n",
      "     |\n",
      "     |      y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n",
      "     |          Target values (None for unsupervised transformations).\n",
      "     |\n",
      "     |      **fit_params : dict\n",
      "     |          Additional fit parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      "     |          Transformed array.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  set_output(self, *, transform=None)\n",
      "     |      Set output container.\n",
      "     |\n",
      "     |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      "     |      for an example on how to use the API.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      transform : {\"default\", \"pandas\", \"polars\"}, default=None\n",
      "     |          Configure output of `transform` and `fit_transform`.\n",
      "     |\n",
      "     |          - `\"default\"`: Default output format of a transformer\n",
      "     |          - `\"pandas\"`: DataFrame output\n",
      "     |          - `\"polars\"`: Polars output\n",
      "     |          - `None`: Transform configuration is unchanged\n",
      "     |\n",
      "     |          .. versionadded:: 1.4\n",
      "     |              `\"polars\"` option was added.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs)\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |\n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "\n",
      "    class RobustScaler(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "     |  RobustScaler(*, with_centering=True, with_scaling=True, quantile_range=(25.0, 75.0), copy=True, unit_variance=False)\n",
      "     |\n",
      "     |  Scale features using statistics that are robust to outliers.\n",
      "     |\n",
      "     |  This Scaler removes the median and scales the data according to\n",
      "     |  the quantile range (defaults to IQR: Interquartile Range).\n",
      "     |  The IQR is the range between the 1st quartile (25th quantile)\n",
      "     |  and the 3rd quartile (75th quantile).\n",
      "     |\n",
      "     |  Centering and scaling happen independently on each feature by\n",
      "     |  computing the relevant statistics on the samples in the training\n",
      "     |  set. Median and interquartile range are then stored to be used on\n",
      "     |  later data using the :meth:`transform` method.\n",
      "     |\n",
      "     |  Standardization of a dataset is a common preprocessing for many machine\n",
      "     |  learning estimators. Typically this is done by removing the mean and\n",
      "     |  scaling to unit variance. However, outliers can often influence the sample\n",
      "     |  mean / variance in a negative way. In such cases, using the median and the\n",
      "     |  interquartile range often give better results. For an example visualization\n",
      "     |  and comparison to other scalers, refer to :ref:`Compare RobustScaler with\n",
      "     |  other scalers <plot_all_scaling_robust_scaler_section>`.\n",
      "     |\n",
      "     |  .. versionadded:: 0.17\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <preprocessing_scaler>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  with_centering : bool, default=True\n",
      "     |      If `True`, center the data before scaling.\n",
      "     |      This will cause :meth:`transform` to raise an exception when attempted\n",
      "     |      on sparse matrices, because centering them entails building a dense\n",
      "     |      matrix which in common use cases is likely to be too large to fit in\n",
      "     |      memory.\n",
      "     |\n",
      "     |  with_scaling : bool, default=True\n",
      "     |      If `True`, scale the data to interquartile range.\n",
      "     |\n",
      "     |  quantile_range : tuple (q_min, q_max), 0.0 < q_min < q_max < 100.0,         default=(25.0, 75.0)\n",
      "     |      Quantile range used to calculate `scale_`. By default this is equal to\n",
      "     |      the IQR, i.e., `q_min` is the first quantile and `q_max` is the third\n",
      "     |      quantile.\n",
      "     |\n",
      "     |      .. versionadded:: 0.18\n",
      "     |\n",
      "     |  copy : bool, default=True\n",
      "     |      If `False`, try to avoid a copy and do inplace scaling instead.\n",
      "     |      This is not guaranteed to always work inplace; e.g. if the data is\n",
      "     |      not a NumPy array or scipy.sparse CSR matrix, a copy may still be\n",
      "     |      returned.\n",
      "     |\n",
      "     |  unit_variance : bool, default=False\n",
      "     |      If `True`, scale data so that normally distributed features have a\n",
      "     |      variance of 1. In general, if the difference between the x-values of\n",
      "     |      `q_max` and `q_min` for a standard normal distribution is greater\n",
      "     |      than 1, the dataset will be scaled down. If less than 1, the dataset\n",
      "     |      will be scaled up.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  center_ : array of floats\n",
      "     |      The median value for each feature in the training set.\n",
      "     |\n",
      "     |  scale_ : array of floats\n",
      "     |      The (scaled) interquartile range for each feature in the training set.\n",
      "     |\n",
      "     |      .. versionadded:: 0.17\n",
      "     |         *scale_* attribute.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  robust_scale : Equivalent function without the estimator API.\n",
      "     |  sklearn.decomposition.PCA : Further removes the linear correlation across\n",
      "     |      features with 'whiten=True'.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |\n",
      "     |  https://en.wikipedia.org/wiki/Median\n",
      "     |  https://en.wikipedia.org/wiki/Interquartile_range\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.preprocessing import RobustScaler\n",
      "     |  >>> X = [[ 1., -2.,  2.],\n",
      "     |  ...      [ -2.,  1.,  3.],\n",
      "     |  ...      [ 4.,  1., -2.]]\n",
      "     |  >>> transformer = RobustScaler().fit(X)\n",
      "     |  >>> transformer\n",
      "     |  RobustScaler()\n",
      "     |  >>> transformer.transform(X)\n",
      "     |  array([[ 0. , -2. ,  0. ],\n",
      "     |         [-1. ,  0. ,  0.4],\n",
      "     |         [ 1. ,  0. , -1.6]])\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      RobustScaler\n",
      "     |      sklearn.base.OneToOneFeatureMixin\n",
      "     |      sklearn.base.TransformerMixin\n",
      "     |      sklearn.utils._set_output._SetOutputMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, with_centering=True, with_scaling=True, quantile_range=(25.0, 75.0), copy=True, unit_variance=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y=None)\n",
      "     |      Compute the median and quantiles to be used for scaling.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data used to compute the median and quantiles\n",
      "     |          used for later scaling along the features axis.\n",
      "     |\n",
      "     |      y : Ignored\n",
      "     |          Not used, present here for API consistency by convention.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted scaler.\n",
      "     |\n",
      "     |  inverse_transform(self, X)\n",
      "     |      Scale back the data to the original representation.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The rescaled data to be transformed back.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Transformed array.\n",
      "     |\n",
      "     |  transform(self, X)\n",
      "     |      Center and scale the data.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data used to scale along the specified axis.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Transformed array.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.OneToOneFeatureMixin:\n",
      "     |\n",
      "     |  get_feature_names_out(self, input_features=None)\n",
      "     |      Get output feature names for transformation.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      input_features : array-like of str or None, default=None\n",
      "     |          Input features.\n",
      "     |\n",
      "     |          - If `input_features` is `None`, then `feature_names_in_` is\n",
      "     |            used as feature names in. If `feature_names_in_` is not defined,\n",
      "     |            then the following input feature names are generated:\n",
      "     |            `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n",
      "     |          - If `input_features` is an array-like, then `input_features` must\n",
      "     |            match `feature_names_in_` if `feature_names_in_` is defined.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      feature_names_out : ndarray of str objects\n",
      "     |          Same as input features.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.OneToOneFeatureMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.TransformerMixin:\n",
      "     |\n",
      "     |  fit_transform(self, X, y=None, **fit_params)\n",
      "     |      Fit to data, then transform it.\n",
      "     |\n",
      "     |      Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
      "     |      and returns a transformed version of `X`.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Input samples.\n",
      "     |\n",
      "     |      y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n",
      "     |          Target values (None for unsupervised transformations).\n",
      "     |\n",
      "     |      **fit_params : dict\n",
      "     |          Additional fit parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      "     |          Transformed array.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  set_output(self, *, transform=None)\n",
      "     |      Set output container.\n",
      "     |\n",
      "     |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      "     |      for an example on how to use the API.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      transform : {\"default\", \"pandas\", \"polars\"}, default=None\n",
      "     |          Configure output of `transform` and `fit_transform`.\n",
      "     |\n",
      "     |          - `\"default\"`: Default output format of a transformer\n",
      "     |          - `\"pandas\"`: DataFrame output\n",
      "     |          - `\"polars\"`: Polars output\n",
      "     |          - `None`: Transform configuration is unchanged\n",
      "     |\n",
      "     |          .. versionadded:: 1.4\n",
      "     |              `\"polars\"` option was added.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs)\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |\n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "\n",
      "    class SplineTransformer(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "     |  SplineTransformer(n_knots=5, degree=3, *, knots='uniform', extrapolation='constant', include_bias=True, order='C', sparse_output=False)\n",
      "     |\n",
      "     |  Generate univariate B-spline bases for features.\n",
      "     |\n",
      "     |  Generate a new feature matrix consisting of\n",
      "     |  `n_splines=n_knots + degree - 1` (`n_knots - 1` for\n",
      "     |  `extrapolation=\"periodic\"`) spline basis functions\n",
      "     |  (B-splines) of polynomial order=`degree` for each feature.\n",
      "     |\n",
      "     |  In order to learn more about the SplineTransformer class go to:\n",
      "     |  :ref:`sphx_glr_auto_examples_applications_plot_cyclical_feature_engineering.py`\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <spline_transformer>`.\n",
      "     |\n",
      "     |  .. versionadded:: 1.0\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  n_knots : int, default=5\n",
      "     |      Number of knots of the splines if `knots` equals one of\n",
      "     |      {'uniform', 'quantile'}. Must be larger or equal 2. Ignored if `knots`\n",
      "     |      is array-like.\n",
      "     |\n",
      "     |  degree : int, default=3\n",
      "     |      The polynomial degree of the spline basis. Must be a non-negative\n",
      "     |      integer.\n",
      "     |\n",
      "     |  knots : {'uniform', 'quantile'} or array-like of shape         (n_knots, n_features), default='uniform'\n",
      "     |      Set knot positions such that first knot <= features <= last knot.\n",
      "     |\n",
      "     |      - If 'uniform', `n_knots` number of knots are distributed uniformly\n",
      "     |        from min to max values of the features.\n",
      "     |      - If 'quantile', they are distributed uniformly along the quantiles of\n",
      "     |        the features.\n",
      "     |      - If an array-like is given, it directly specifies the sorted knot\n",
      "     |        positions including the boundary knots. Note that, internally,\n",
      "     |        `degree` number of knots are added before the first knot, the same\n",
      "     |        after the last knot.\n",
      "     |\n",
      "     |  extrapolation : {'error', 'constant', 'linear', 'continue', 'periodic'},         default='constant'\n",
      "     |      If 'error', values outside the min and max values of the training\n",
      "     |      features raises a `ValueError`. If 'constant', the value of the\n",
      "     |      splines at minimum and maximum value of the features is used as\n",
      "     |      constant extrapolation. If 'linear', a linear extrapolation is used.\n",
      "     |      If 'continue', the splines are extrapolated as is, i.e. option\n",
      "     |      `extrapolate=True` in :class:`scipy.interpolate.BSpline`. If\n",
      "     |      'periodic', periodic splines with a periodicity equal to the distance\n",
      "     |      between the first and last knot are used. Periodic splines enforce\n",
      "     |      equal function values and derivatives at the first and last knot.\n",
      "     |      For example, this makes it possible to avoid introducing an arbitrary\n",
      "     |      jump between Dec 31st and Jan 1st in spline features derived from a\n",
      "     |      naturally periodic \"day-of-year\" input feature. In this case it is\n",
      "     |      recommended to manually set the knot values to control the period.\n",
      "     |\n",
      "     |  include_bias : bool, default=True\n",
      "     |      If False, then the last spline element inside the data range\n",
      "     |      of a feature is dropped. As B-splines sum to one over the spline basis\n",
      "     |      functions for each data point, they implicitly include a bias term,\n",
      "     |      i.e. a column of ones. It acts as an intercept term in a linear models.\n",
      "     |\n",
      "     |  order : {'C', 'F'}, default='C'\n",
      "     |      Order of output array in the dense case. `'F'` order is faster to compute, but\n",
      "     |      may slow down subsequent estimators.\n",
      "     |\n",
      "     |  sparse_output : bool, default=False\n",
      "     |      Will return sparse CSR matrix if set True else will return an array. This\n",
      "     |      option is only available with `scipy>=1.8`.\n",
      "     |\n",
      "     |      .. versionadded:: 1.2\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  bsplines_ : list of shape (n_features,)\n",
      "     |      List of BSplines objects, one for each feature.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      The total number of input features.\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  n_features_out_ : int\n",
      "     |      The total number of output features, which is computed as\n",
      "     |      `n_features * n_splines`, where `n_splines` is\n",
      "     |      the number of bases elements of the B-splines,\n",
      "     |      `n_knots + degree - 1` for non-periodic splines and\n",
      "     |      `n_knots - 1` for periodic ones.\n",
      "     |      If `include_bias=False`, then it is only\n",
      "     |      `n_features * (n_splines - 1)`.\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  KBinsDiscretizer : Transformer that bins continuous data into intervals.\n",
      "     |\n",
      "     |  PolynomialFeatures : Transformer that generates polynomial and interaction\n",
      "     |      features.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  High degrees and a high number of knots can cause overfitting.\n",
      "     |\n",
      "     |  See :ref:`examples/linear_model/plot_polynomial_interpolation.py\n",
      "     |  <sphx_glr_auto_examples_linear_model_plot_polynomial_interpolation.py>`.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.preprocessing import SplineTransformer\n",
      "     |  >>> X = np.arange(6).reshape(6, 1)\n",
      "     |  >>> spline = SplineTransformer(degree=2, n_knots=3)\n",
      "     |  >>> spline.fit_transform(X)\n",
      "     |  array([[0.5 , 0.5 , 0.  , 0.  ],\n",
      "     |         [0.18, 0.74, 0.08, 0.  ],\n",
      "     |         [0.02, 0.66, 0.32, 0.  ],\n",
      "     |         [0.  , 0.32, 0.66, 0.02],\n",
      "     |         [0.  , 0.08, 0.74, 0.18],\n",
      "     |         [0.  , 0.  , 0.5 , 0.5 ]])\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      SplineTransformer\n",
      "     |      sklearn.base.TransformerMixin\n",
      "     |      sklearn.utils._set_output._SetOutputMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, n_knots=5, degree=3, *, knots='uniform', extrapolation='constant', include_bias=True, order='C', sparse_output=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y=None, sample_weight=None)\n",
      "     |      Compute knot positions of splines.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The data.\n",
      "     |\n",
      "     |      y : None\n",
      "     |          Ignored.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default = None\n",
      "     |          Individual weights for each sample. Used to calculate quantiles if\n",
      "     |          `knots=\"quantile\"`. For `knots=\"uniform\"`, zero weighted\n",
      "     |          observations are ignored for finding the min and max of `X`.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted transformer.\n",
      "     |\n",
      "     |  get_feature_names_out(self, input_features=None)\n",
      "     |      Get output feature names for transformation.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      input_features : array-like of str or None, default=None\n",
      "     |          Input features.\n",
      "     |\n",
      "     |          - If `input_features` is `None`, then `feature_names_in_` is\n",
      "     |            used as feature names in. If `feature_names_in_` is not defined,\n",
      "     |            then the following input feature names are generated:\n",
      "     |            `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n",
      "     |          - If `input_features` is an array-like, then `input_features` must\n",
      "     |            match `feature_names_in_` if `feature_names_in_` is defined.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      feature_names_out : ndarray of str objects\n",
      "     |          Transformed feature names.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.preprocessing._polynomial.SplineTransformer, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.preprocessing._polynomial.SplineTransformer from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  transform(self, X)\n",
      "     |      Transform each feature data to B-splines.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The data to transform.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      XBS : {ndarray, sparse matrix} of shape (n_samples, n_features * n_splines)\n",
      "     |          The matrix of features, where n_splines is the number of bases\n",
      "     |          elements of the B-splines, n_knots + degree - 1.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.TransformerMixin:\n",
      "     |\n",
      "     |  fit_transform(self, X, y=None, **fit_params)\n",
      "     |      Fit to data, then transform it.\n",
      "     |\n",
      "     |      Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
      "     |      and returns a transformed version of `X`.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Input samples.\n",
      "     |\n",
      "     |      y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n",
      "     |          Target values (None for unsupervised transformations).\n",
      "     |\n",
      "     |      **fit_params : dict\n",
      "     |          Additional fit parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      "     |          Transformed array.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  set_output(self, *, transform=None)\n",
      "     |      Set output container.\n",
      "     |\n",
      "     |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      "     |      for an example on how to use the API.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      transform : {\"default\", \"pandas\", \"polars\"}, default=None\n",
      "     |          Configure output of `transform` and `fit_transform`.\n",
      "     |\n",
      "     |          - `\"default\"`: Default output format of a transformer\n",
      "     |          - `\"pandas\"`: DataFrame output\n",
      "     |          - `\"polars\"`: Polars output\n",
      "     |          - `None`: Transform configuration is unchanged\n",
      "     |\n",
      "     |          .. versionadded:: 1.4\n",
      "     |              `\"polars\"` option was added.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs)\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |\n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |\n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |\n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "\n",
      "    class StandardScaler(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      "     |  StandardScaler(*, copy=True, with_mean=True, with_std=True)\n",
      "     |\n",
      "     |  Standardize features by removing the mean and scaling to unit variance.\n",
      "     |\n",
      "     |  The standard score of a sample `x` is calculated as:\n",
      "     |\n",
      "     |      z = (x - u) / s\n",
      "     |\n",
      "     |  where `u` is the mean of the training samples or zero if `with_mean=False`,\n",
      "     |  and `s` is the standard deviation of the training samples or one if\n",
      "     |  `with_std=False`.\n",
      "     |\n",
      "     |  Centering and scaling happen independently on each feature by computing\n",
      "     |  the relevant statistics on the samples in the training set. Mean and\n",
      "     |  standard deviation are then stored to be used on later data using\n",
      "     |  :meth:`transform`.\n",
      "     |\n",
      "     |  Standardization of a dataset is a common requirement for many\n",
      "     |  machine learning estimators: they might behave badly if the\n",
      "     |  individual features do not more or less look like standard normally\n",
      "     |  distributed data (e.g. Gaussian with 0 mean and unit variance).\n",
      "     |\n",
      "     |  For instance many elements used in the objective function of\n",
      "     |  a learning algorithm (such as the RBF kernel of Support Vector\n",
      "     |  Machines or the L1 and L2 regularizers of linear models) assume that\n",
      "     |  all features are centered around 0 and have variance in the same\n",
      "     |  order. If a feature has a variance that is orders of magnitude larger\n",
      "     |  than others, it might dominate the objective function and make the\n",
      "     |  estimator unable to learn from other features correctly as expected.\n",
      "     |\n",
      "     |  `StandardScaler` is sensitive to outliers, and the features may scale\n",
      "     |  differently from each other in the presence of outliers. For an example\n",
      "     |  visualization, refer to :ref:`Compare StandardScaler with other scalers\n",
      "     |  <plot_all_scaling_standard_scaler_section>`.\n",
      "     |\n",
      "     |  This scaler can also be applied to sparse CSR or CSC matrices by passing\n",
      "     |  `with_mean=False` to avoid breaking the sparsity structure of the data.\n",
      "     |\n",
      "     |  Read more in the :ref:`User Guide <preprocessing_scaler>`.\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  copy : bool, default=True\n",
      "     |      If False, try to avoid a copy and do inplace scaling instead.\n",
      "     |      This is not guaranteed to always work inplace; e.g. if the data is\n",
      "     |      not a NumPy array or scipy.sparse CSR matrix, a copy may still be\n",
      "     |      returned.\n",
      "     |\n",
      "     |  with_mean : bool, default=True\n",
      "     |      If True, center the data before scaling.\n",
      "     |      This does not work (and will raise an exception) when attempted on\n",
      "     |      sparse matrices, because centering them entails building a dense\n",
      "     |      matrix which in common use cases is likely to be too large to fit in\n",
      "     |      memory.\n",
      "     |\n",
      "     |  with_std : bool, default=True\n",
      "     |      If True, scale the data to unit variance (or equivalently,\n",
      "     |      unit standard deviation).\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  scale_ : ndarray of shape (n_features,) or None\n",
      "     |      Per feature relative scaling of the data to achieve zero mean and unit\n",
      "     |      variance. Generally this is calculated using `np.sqrt(var_)`. If a\n",
      "     |      variance is zero, we can't achieve unit variance, and the data is left\n",
      "     |      as-is, giving a scaling factor of 1. `scale_` is equal to `None`\n",
      "     |      when `with_std=False`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.17\n",
      "     |         *scale_*\n",
      "     |\n",
      "     |  mean_ : ndarray of shape (n_features,) or None\n",
      "     |      The mean value for each feature in the training set.\n",
      "     |      Equal to ``None`` when ``with_mean=False`` and ``with_std=False``.\n",
      "     |\n",
      "     |  var_ : ndarray of shape (n_features,) or None\n",
      "     |      The variance for each feature in the training set. Used to compute\n",
      "     |      `scale_`. Equal to ``None`` when ``with_mean=False`` and\n",
      "     |      ``with_std=False``.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |      .. versionadded:: 0.24\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |      .. versionadded:: 1.0\n",
      "     |\n",
      "     |  n_samples_seen_ : int or ndarray of shape (n_features,)\n",
      "     |      The number of samples processed by the estimator for each feature.\n",
      "     |      If there are no missing samples, the ``n_samples_seen`` will be an\n",
      "     |      integer, otherwise it will be an array of dtype int. If\n",
      "     |      `sample_weights` are used it will be a float (if no missing data)\n",
      "     |      or an array of dtype float that sums the weights seen so far.\n",
      "     |      Will be reset on new calls to fit, but increments across\n",
      "     |      ``partial_fit`` calls.\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  scale : Equivalent function without the estimator API.\n",
      "     |\n",
      "     |  :class:`~sklearn.decomposition.PCA` : Further removes the linear\n",
      "     |      correlation across features with 'whiten=True'.\n",
      "     |\n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  NaNs are treated as missing values: disregarded in fit, and maintained in\n",
      "     |  transform.\n",
      "     |\n",
      "     |  We use a biased estimator for the standard deviation, equivalent to\n",
      "     |  `numpy.std(x, ddof=0)`. Note that the choice of `ddof` is unlikely to\n",
      "     |  affect model performance.\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.preprocessing import StandardScaler\n",
      "     |  >>> data = [[0, 0], [0, 0], [1, 1], [1, 1]]\n",
      "     |  >>> scaler = StandardScaler()\n",
      "     |  >>> print(scaler.fit(data))\n",
      "     |  StandardScaler()\n",
      "     |  >>> print(scaler.mean_)\n",
      "     |  [0.5 0.5]\n",
      "     |  >>> print(scaler.transform(data))\n",
      "     |  [[-1. -1.]\n",
      "     |   [-1. -1.]\n",
      "     |   [ 1.  1.]\n",
      "     |   [ 1.  1.]]\n",
      "     |  >>> print(scaler.transform([[2, 2]]))\n",
      "     |  [[3. 3.]]\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      StandardScaler\n",
      "     |      sklearn.base.OneToOneFeatureMixin\n",
      "     |      sklearn.base.TransformerMixin\n",
      "     |      sklearn.utils._set_output._SetOutputMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, *, copy=True, with_mean=True, with_std=True)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y=None, sample_weight=None)\n",
      "     |      Compute the mean and std to be used for later scaling.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data used to compute the mean and standard deviation\n",
      "     |          used for later scaling along the features axis.\n",
      "     |\n",
      "     |      y : None\n",
      "     |          Ignored.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Individual weights for each sample.\n",
      "     |\n",
      "     |          .. versionadded:: 0.24\n",
      "     |             parameter *sample_weight* support to StandardScaler.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted scaler.\n",
      "     |\n",
      "     |  inverse_transform(self, X, copy=None)\n",
      "     |      Scale back the data to the original representation.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data used to scale along the features axis.\n",
      "     |      copy : bool, default=None\n",
      "     |          Copy the input X or not.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Transformed array.\n",
      "     |\n",
      "     |  partial_fit(self, X, y=None, sample_weight=None)\n",
      "     |      Online computation of mean and std on X for later scaling.\n",
      "     |\n",
      "     |      All of X is processed as a single batch. This is intended for cases\n",
      "     |      when :meth:`fit` is not feasible due to very large number of\n",
      "     |      `n_samples` or because X is read from a continuous stream.\n",
      "     |\n",
      "     |      The algorithm for incremental mean and std is given in Equation 1.5a,b\n",
      "     |      in Chan, Tony F., Gene H. Golub, and Randall J. LeVeque. \"Algorithms\n",
      "     |      for computing the sample variance: Analysis and recommendations.\"\n",
      "     |      The American Statistician 37.3 (1983): 242-247:\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          The data used to compute the mean and standard deviation\n",
      "     |          used for later scaling along the features axis.\n",
      "     |\n",
      "     |      y : None\n",
      "     |          Ignored.\n",
      "     |\n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Individual weights for each sample.\n",
      "     |\n",
      "     |          .. versionadded:: 0.24\n",
      "     |             parameter *sample_weight* support to StandardScaler.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted scaler.\n",
      "     |\n",
      "     |  set_fit_request(self: sklearn.preprocessing._data.StandardScaler, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.preprocessing._data.StandardScaler from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_inverse_transform_request(self: sklearn.preprocessing._data.StandardScaler, *, copy: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.preprocessing._data.StandardScaler from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
      "     |      Request metadata passed to the ``inverse_transform`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``inverse_transform`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``inverse_transform``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      copy : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``copy`` parameter in ``inverse_transform``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_partial_fit_request(self: sklearn.preprocessing._data.StandardScaler, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.preprocessing._data.StandardScaler from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
      "     |      Request metadata passed to the ``partial_fit`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``partial_fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``partial_fit``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``partial_fit``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  set_transform_request(self: sklearn.preprocessing._data.StandardScaler, *, copy: Union[bool, NoneType, str] = '$UNCHANGED$') -> sklearn.preprocessing._data.StandardScaler from sklearn.utils._metadata_requests.RequestMethod.__get__.<locals>\n",
      "     |      Request metadata passed to the ``transform`` method.\n",
      "     |\n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      The options for each parameter are:\n",
      "     |\n",
      "     |      - ``True``: metadata is requested, and passed to ``transform`` if provided. The request is ignored if metadata is not provided.\n",
      "     |\n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``transform``.\n",
      "     |\n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |\n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |\n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |\n",
      "     |      .. versionadded:: 1.3\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      copy : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``copy`` parameter in ``transform``.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |\n",
      "     |  transform(self, X, copy=None)\n",
      "     |      Perform standardization by centering and scaling.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : {array-like, sparse matrix of shape (n_samples, n_features)\n",
      "     |          The data used to scale along the features axis.\n",
      "     |      copy : bool, default=None\n",
      "     |          Copy the input X or not.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Transformed array.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.OneToOneFeatureMixin:\n",
      "     |\n",
      "     |  get_feature_names_out(self, input_features=None)\n",
      "     |      Get output feature names for transformation.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      input_features : array-like of str or None, default=None\n",
      "     |          Input features.\n",
      "     |\n",
      "     |          - If `input_features` is `None`, then `feature_names_in_` is\n",
      "     |            used as feature names in. If `feature_names_in_` is not defined,\n",
      "     |            then the following input feature names are generated:\n",
      "     |            `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n",
      "     |          - If `input_features` is an array-like, then `input_features` must\n",
      "     |            match `feature_names_in_` if `feature_names_in_` is defined.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      feature_names_out : ndarray of str objects\n",
      "     |          Same as input features.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.OneToOneFeatureMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.TransformerMixin:\n",
      "     |\n",
      "     |  fit_transform(self, X, y=None, **fit_params)\n",
      "     |      Fit to data, then transform it.\n",
      "     |\n",
      "     |      Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
      "     |      and returns a transformed version of `X`.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Input samples.\n",
      "     |\n",
      "     |      y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n",
      "     |          Target values (None for unsupervised transformations).\n",
      "     |\n",
      "     |      **fit_params : dict\n",
      "     |          Additional fit parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      "     |          Transformed array.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  set_output(self, *, transform=None)\n",
      "     |      Set output container.\n",
      "     |\n",
      "     |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      "     |      for an example on how to use the API.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      transform : {\"default\", \"pandas\", \"polars\"}, default=None\n",
      "     |          Configure output of `transform` and `fit_transform`.\n",
      "     |\n",
      "     |          - `\"default\"`: Default output format of a transformer\n",
      "     |          - `\"pandas\"`: DataFrame output\n",
      "     |          - `\"polars\"`: Polars output\n",
      "     |          - `None`: Transform configuration is unchanged\n",
      "     |\n",
      "     |          .. versionadded:: 1.4\n",
      "     |              `\"polars\"` option was added.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs)\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |\n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "\n",
      "    class TargetEncoder(sklearn.base.OneToOneFeatureMixin, sklearn.preprocessing._encoders._BaseEncoder)\n",
      "     |  TargetEncoder(categories='auto', target_type='auto', smooth='auto', cv=5, shuffle=True, random_state=None)\n",
      "     |\n",
      "     |  Target Encoder for regression and classification targets.\n",
      "     |\n",
      "     |  Each category is encoded based on a shrunk estimate of the average target\n",
      "     |  values for observations belonging to the category. The encoding scheme mixes\n",
      "     |  the global target mean with the target mean conditioned on the value of the\n",
      "     |  category (see [MIC]_).\n",
      "     |\n",
      "     |  When the target type is \"multiclass\", encodings are based\n",
      "     |  on the conditional probability estimate for each class. The target is first\n",
      "     |  binarized using the \"one-vs-all\" scheme via\n",
      "     |  :class:`~sklearn.preprocessing.LabelBinarizer`, then the average target\n",
      "     |  value for each class and each category is used for encoding, resulting in\n",
      "     |  `n_features` * `n_classes` encoded output features.\n",
      "     |\n",
      "     |  :class:`TargetEncoder` considers missing values, such as `np.nan` or `None`,\n",
      "     |  as another category and encodes them like any other category. Categories\n",
      "     |  that are not seen during :meth:`fit` are encoded with the target mean, i.e.\n",
      "     |  `target_mean_`.\n",
      "     |\n",
      "     |  For a demo on the importance of the `TargetEncoder` internal cross-fitting,\n",
      "     |  see\n",
      "     |  :ref:`sphx_glr_auto_examples_preprocessing_plot_target_encoder_cross_val.py`.\n",
      "     |  For a comparison of different encoders, refer to\n",
      "     |  :ref:`sphx_glr_auto_examples_preprocessing_plot_target_encoder.py`. Read\n",
      "     |  more in the :ref:`User Guide <target_encoder>`.\n",
      "     |\n",
      "     |  .. note::\n",
      "     |      `fit(X, y).transform(X)` does not equal `fit_transform(X, y)` because a\n",
      "     |      :term:`cross fitting` scheme is used in `fit_transform` for encoding.\n",
      "     |      See the :ref:`User Guide <target_encoder>` for details.\n",
      "     |\n",
      "     |  .. versionadded:: 1.3\n",
      "     |\n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  categories : \"auto\" or list of shape (n_features,) of array-like, default=\"auto\"\n",
      "     |      Categories (unique values) per feature:\n",
      "     |\n",
      "     |      - `\"auto\"` : Determine categories automatically from the training data.\n",
      "     |      - list : `categories[i]` holds the categories expected in the i-th column. The\n",
      "     |        passed categories should not mix strings and numeric values within a single\n",
      "     |        feature, and should be sorted in case of numeric values.\n",
      "     |\n",
      "     |      The used categories are stored in the `categories_` fitted attribute.\n",
      "     |\n",
      "     |  target_type : {\"auto\", \"continuous\", \"binary\", \"multiclass\"}, default=\"auto\"\n",
      "     |      Type of target.\n",
      "     |\n",
      "     |      - `\"auto\"` : Type of target is inferred with\n",
      "     |        :func:`~sklearn.utils.multiclass.type_of_target`.\n",
      "     |      - `\"continuous\"` : Continuous target\n",
      "     |      - `\"binary\"` : Binary target\n",
      "     |      - `\"multiclass\"` : Multiclass target\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          The type of target inferred with `\"auto\"` may not be the desired target\n",
      "     |          type used for modeling. For example, if the target consisted of integers\n",
      "     |          between 0 and 100, then :func:`~sklearn.utils.multiclass.type_of_target`\n",
      "     |          will infer the target as `\"multiclass\"`. In this case, setting\n",
      "     |          `target_type=\"continuous\"` will specify the target as a regression\n",
      "     |          problem. The `target_type_` attribute gives the target type used by the\n",
      "     |          encoder.\n",
      "     |\n",
      "     |      .. versionchanged:: 1.4\n",
      "     |         Added the option 'multiclass'.\n",
      "     |\n",
      "     |  smooth : \"auto\" or float, default=\"auto\"\n",
      "     |      The amount of mixing of the target mean conditioned on the value of the\n",
      "     |      category with the global target mean. A larger `smooth` value will put\n",
      "     |      more weight on the global target mean.\n",
      "     |      If `\"auto\"`, then `smooth` is set to an empirical Bayes estimate.\n",
      "     |\n",
      "     |  cv : int, default=5\n",
      "     |      Determines the number of folds in the :term:`cross fitting` strategy used in\n",
      "     |      :meth:`fit_transform`. For classification targets, `StratifiedKFold` is used\n",
      "     |      and for continuous targets, `KFold` is used.\n",
      "     |\n",
      "     |  shuffle : bool, default=True\n",
      "     |      Whether to shuffle the data in :meth:`fit_transform` before splitting into\n",
      "     |      folds. Note that the samples within each split will not be shuffled.\n",
      "     |\n",
      "     |  random_state : int, RandomState instance or None, default=None\n",
      "     |      When `shuffle` is True, `random_state` affects the ordering of the\n",
      "     |      indices, which controls the randomness of each fold. Otherwise, this\n",
      "     |      parameter has no effect.\n",
      "     |      Pass an int for reproducible output across multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |\n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  encodings_ : list of shape (n_features,) or (n_features * n_classes) of                     ndarray\n",
      "     |      Encodings learnt on all of `X`.\n",
      "     |      For feature `i`, `encodings_[i]` are the encodings matching the\n",
      "     |      categories listed in `categories_[i]`. When `target_type_` is\n",
      "     |      \"multiclass\", the encoding for feature `i` and class `j` is stored in\n",
      "     |      `encodings_[j + (i * len(classes_))]`. E.g., for 2 features (f) and\n",
      "     |      3 classes (c), encodings are ordered:\n",
      "     |      f0_c0, f0_c1, f0_c2, f1_c0, f1_c1, f1_c2,\n",
      "     |\n",
      "     |  categories_ : list of shape (n_features,) of ndarray\n",
      "     |      The categories of each input feature determined during fitting or\n",
      "     |      specified in `categories`\n",
      "     |      (in order of the features in `X` and corresponding with the output\n",
      "     |      of :meth:`transform`).\n",
      "     |\n",
      "     |  target_type_ : str\n",
      "     |      Type of target.\n",
      "     |\n",
      "     |  target_mean_ : float\n",
      "     |      The overall mean of the target. This value is only used in :meth:`transform`\n",
      "     |      to encode categories.\n",
      "     |\n",
      "     |  n_features_in_ : int\n",
      "     |      Number of features seen during :term:`fit`.\n",
      "     |\n",
      "     |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "     |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      "     |      has feature names that are all strings.\n",
      "     |\n",
      "     |  classes_ : ndarray or None\n",
      "     |      If `target_type_` is 'binary' or 'multiclass', holds the label for each class,\n",
      "     |      otherwise `None`.\n",
      "     |\n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  OrdinalEncoder : Performs an ordinal (integer) encoding of the categorical features.\n",
      "     |      Contrary to TargetEncoder, this encoding is not supervised. Treating the\n",
      "     |      resulting encoding as a numerical features therefore lead arbitrarily\n",
      "     |      ordered values and therefore typically lead to lower predictive performance\n",
      "     |      when used as preprocessing for a classifier or regressor.\n",
      "     |  OneHotEncoder : Performs a one-hot encoding of categorical features. This\n",
      "     |      unsupervised encoding is better suited for low cardinality categorical\n",
      "     |      variables as it generate one new feature per unique category.\n",
      "     |\n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  .. [MIC] :doi:`Micci-Barreca, Daniele. \"A preprocessing scheme for high-cardinality\n",
      "     |     categorical attributes in classification and prediction problems\"\n",
      "     |     SIGKDD Explor. Newsl. 3, 1 (July 2001), 27–32. <10.1145/507533.507538>`\n",
      "     |\n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  With `smooth=\"auto\"`, the smoothing parameter is set to an empirical Bayes estimate:\n",
      "     |\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.preprocessing import TargetEncoder\n",
      "     |  >>> X = np.array([[\"dog\"] * 20 + [\"cat\"] * 30 + [\"snake\"] * 38], dtype=object).T\n",
      "     |  >>> y = [90.3] * 5 + [80.1] * 15 + [20.4] * 5 + [20.1] * 25 + [21.2] * 8 + [49] * 30\n",
      "     |  >>> enc_auto = TargetEncoder(smooth=\"auto\")\n",
      "     |  >>> X_trans = enc_auto.fit_transform(X, y)\n",
      "     |\n",
      "     |  >>> # A high `smooth` parameter puts more weight on global mean on the categorical\n",
      "     |  >>> # encodings:\n",
      "     |  >>> enc_high_smooth = TargetEncoder(smooth=5000.0).fit(X, y)\n",
      "     |  >>> enc_high_smooth.target_mean_\n",
      "     |  np.float64(44...)\n",
      "     |  >>> enc_high_smooth.encodings_\n",
      "     |  [array([44..., 44..., 44...])]\n",
      "     |\n",
      "     |  >>> # On the other hand, a low `smooth` parameter puts more weight on target\n",
      "     |  >>> # conditioned on the value of the categorical:\n",
      "     |  >>> enc_low_smooth = TargetEncoder(smooth=1.0).fit(X, y)\n",
      "     |  >>> enc_low_smooth.encodings_\n",
      "     |  [array([20..., 80..., 43...])]\n",
      "     |\n",
      "     |  Method resolution order:\n",
      "     |      TargetEncoder\n",
      "     |      sklearn.base.OneToOneFeatureMixin\n",
      "     |      sklearn.preprocessing._encoders._BaseEncoder\n",
      "     |      sklearn.base.TransformerMixin\n",
      "     |      sklearn.utils._set_output._SetOutputMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |\n",
      "     |  Methods defined here:\n",
      "     |\n",
      "     |  __init__(self, categories='auto', target_type='auto', smooth='auto', cv=5, shuffle=True, random_state=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |\n",
      "     |  fit(self, X, y)\n",
      "     |      Fit the :class:`TargetEncoder` to X and y.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The data to determine the categories of each feature.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          The target data used to encode the categories.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Fitted encoder.\n",
      "     |\n",
      "     |  fit_transform(self, X, y)\n",
      "     |      Fit :class:`TargetEncoder` and transform X with the target encoding.\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          `fit(X, y).transform(X)` does not equal `fit_transform(X, y)` because a\n",
      "     |          :term:`cross fitting` scheme is used in `fit_transform` for encoding.\n",
      "     |          See the :ref:`User Guide <target_encoder>`. for details.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The data to determine the categories of each feature.\n",
      "     |\n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          The target data used to encode the categories.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_trans : ndarray of shape (n_samples, n_features) or                     (n_samples, (n_features * n_classes))\n",
      "     |          Transformed input.\n",
      "     |\n",
      "     |  get_feature_names_out(self, input_features=None)\n",
      "     |      Get output feature names for transformation.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      input_features : array-like of str or None, default=None\n",
      "     |          Not used, present here for API consistency by convention.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      feature_names_out : ndarray of str objects\n",
      "     |          Transformed feature names. `feature_names_in_` is used unless it is\n",
      "     |          not defined, in which case the following input feature names are\n",
      "     |          generated: `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n",
      "     |          When `type_of_target_` is \"multiclass\" the names are of the format\n",
      "     |          '<feature_name>_<class_name>'.\n",
      "     |\n",
      "     |  transform(self, X)\n",
      "     |      Transform X with the target encoding.\n",
      "     |\n",
      "     |      .. note::\n",
      "     |          `fit(X, y).transform(X)` does not equal `fit_transform(X, y)` because a\n",
      "     |          :term:`cross fitting` scheme is used in `fit_transform` for encoding.\n",
      "     |          See the :ref:`User Guide <target_encoder>`. for details.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          The data to determine the categories of each feature.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_trans : ndarray of shape (n_samples, n_features) or                     (n_samples, (n_features * n_classes))\n",
      "     |          Transformed input.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |\n",
      "     |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.OneToOneFeatureMixin:\n",
      "     |\n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables\n",
      "     |\n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from sklearn.preprocessing._encoders._BaseEncoder:\n",
      "     |\n",
      "     |  infrequent_categories_\n",
      "     |      Infrequent categories for each feature.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  set_output(self, *, transform=None)\n",
      "     |      Set output container.\n",
      "     |\n",
      "     |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      "     |      for an example on how to use the API.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      transform : {\"default\", \"pandas\", \"polars\"}, default=None\n",
      "     |          Configure output of `transform` and `fit_transform`.\n",
      "     |\n",
      "     |          - `\"default\"`: Default output format of a transformer\n",
      "     |          - `\"pandas\"`: DataFrame output\n",
      "     |          - `\"polars\"`: Polars output\n",
      "     |          - `None`: Transform configuration is unchanged\n",
      "     |\n",
      "     |          .. versionadded:: 1.4\n",
      "     |              `\"polars\"` option was added.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      "     |\n",
      "     |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs)\n",
      "     |      This method is called when a class is subclassed.\n",
      "     |\n",
      "     |      The default implementation does nothing. It may be\n",
      "     |      overridden to extend subclasses.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |\n",
      "     |  __getstate__(self)\n",
      "     |      Helper for pickle.\n",
      "     |\n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |\n",
      "     |  __setstate__(self, state)\n",
      "     |\n",
      "     |  __sklearn_clone__(self)\n",
      "     |\n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict\n",
      "     |          Parameter names mapped to their values.\n",
      "     |\n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |\n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      "     |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      "     |      possible to update each component of a nested object.\n",
      "     |\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : estimator instance\n",
      "     |          Estimator instance.\n",
      "     |\n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |\n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |\n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "\n",
      "FUNCTIONS\n",
      "    add_dummy_feature(X, value=1.0)\n",
      "        Augment dataset with an additional dummy feature.\n",
      "\n",
      "        This is useful for fitting an intercept term with implementations which\n",
      "        cannot otherwise fit it directly.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            Data.\n",
      "\n",
      "        value : float\n",
      "            Value to use for the dummy feature.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        X : {ndarray, sparse matrix} of shape (n_samples, n_features + 1)\n",
      "            Same data with dummy feature added as first column.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.preprocessing import add_dummy_feature\n",
      "        >>> add_dummy_feature([[0, 1], [1, 0]])\n",
      "        array([[1., 0., 1.],\n",
      "               [1., 1., 0.]])\n",
      "\n",
      "    binarize(X, *, threshold=0.0, copy=True)\n",
      "        Boolean thresholding of array-like or scipy.sparse matrix.\n",
      "\n",
      "        Read more in the :ref:`User Guide <preprocessing_binarization>`.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The data to binarize, element by element.\n",
      "            scipy.sparse matrices should be in CSR or CSC format to avoid an\n",
      "            un-necessary copy.\n",
      "\n",
      "        threshold : float, default=0.0\n",
      "            Feature values below or equal to this are replaced by 0, above it by 1.\n",
      "            Threshold may not be less than 0 for operations on sparse matrices.\n",
      "\n",
      "        copy : bool, default=True\n",
      "            If False, try to avoid a copy and binarize in place.\n",
      "            This is not guaranteed to always work in place; e.g. if the data is\n",
      "            a numpy array with an object dtype, a copy will be returned even with\n",
      "            copy=False.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      "            The transformed data.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        Binarizer : Performs binarization using the Transformer API\n",
      "            (e.g. as part of a preprocessing :class:`~sklearn.pipeline.Pipeline`).\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.preprocessing import binarize\n",
      "        >>> X = [[0.4, 0.6, 0.5], [0.6, 0.1, 0.2]]\n",
      "        >>> binarize(X, threshold=0.5)\n",
      "        array([[0., 1., 0.],\n",
      "               [1., 0., 0.]])\n",
      "\n",
      "    label_binarize(y, *, classes, neg_label=0, pos_label=1, sparse_output=False)\n",
      "        Binarize labels in a one-vs-all fashion.\n",
      "\n",
      "        Several regression and binary classification algorithms are\n",
      "        available in scikit-learn. A simple way to extend these algorithms\n",
      "        to the multi-class classification case is to use the so-called\n",
      "        one-vs-all scheme.\n",
      "\n",
      "        This function makes it possible to compute this transformation for a\n",
      "        fixed set of class labels known ahead of time.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        y : array-like or sparse matrix\n",
      "            Sequence of integer labels or multilabel data to encode.\n",
      "\n",
      "        classes : array-like of shape (n_classes,)\n",
      "            Uniquely holds the label for each class.\n",
      "\n",
      "        neg_label : int, default=0\n",
      "            Value with which negative labels must be encoded.\n",
      "\n",
      "        pos_label : int, default=1\n",
      "            Value with which positive labels must be encoded.\n",
      "\n",
      "        sparse_output : bool, default=False,\n",
      "            Set to true if output binary array is desired in CSR sparse format.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        Y : {ndarray, sparse matrix} of shape (n_samples, n_classes)\n",
      "            Shape will be (n_samples, 1) for binary problems. Sparse matrix will\n",
      "            be of CSR format.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        LabelBinarizer : Class used to wrap the functionality of label_binarize and\n",
      "            allow for fitting to classes independently of the transform operation.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.preprocessing import label_binarize\n",
      "        >>> label_binarize([1, 6], classes=[1, 2, 4, 6])\n",
      "        array([[1, 0, 0, 0],\n",
      "               [0, 0, 0, 1]])\n",
      "\n",
      "        The class ordering is preserved:\n",
      "\n",
      "        >>> label_binarize([1, 6], classes=[1, 6, 4, 2])\n",
      "        array([[1, 0, 0, 0],\n",
      "               [0, 1, 0, 0]])\n",
      "\n",
      "        Binary targets transform to a column vector\n",
      "\n",
      "        >>> label_binarize(['yes', 'no', 'no', 'yes'], classes=['no', 'yes'])\n",
      "        array([[1],\n",
      "               [0],\n",
      "               [0],\n",
      "               [1]])\n",
      "\n",
      "    maxabs_scale(X, *, axis=0, copy=True)\n",
      "        Scale each feature to the [-1, 1] range without breaking the sparsity.\n",
      "\n",
      "        This estimator scales each feature individually such\n",
      "        that the maximal absolute value of each feature in the\n",
      "        training set will be 1.0.\n",
      "\n",
      "        This scaler can also be applied to sparse CSR or CSC matrices.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The data.\n",
      "\n",
      "        axis : {0, 1}, default=0\n",
      "            Axis used to scale along. If 0, independently scale each feature,\n",
      "            otherwise (if 1) scale each sample.\n",
      "\n",
      "        copy : bool, default=True\n",
      "            If False, try to avoid a copy and scale in place.\n",
      "            This is not guaranteed to always work in place; e.g. if the data is\n",
      "            a numpy array with an int dtype, a copy will be returned even with\n",
      "            copy=False.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      "            The transformed data.\n",
      "\n",
      "        .. warning:: Risk of data leak\n",
      "\n",
      "            Do not use :func:`~sklearn.preprocessing.maxabs_scale` unless you know\n",
      "            what you are doing. A common mistake is to apply it to the entire data\n",
      "            *before* splitting into training and test sets. This will bias the\n",
      "            model evaluation because information would have leaked from the test\n",
      "            set to the training set.\n",
      "            In general, we recommend using\n",
      "            :class:`~sklearn.preprocessing.MaxAbsScaler` within a\n",
      "            :ref:`Pipeline <pipeline>` in order to prevent most risks of data\n",
      "            leaking: `pipe = make_pipeline(MaxAbsScaler(), LogisticRegression())`.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        MaxAbsScaler : Performs scaling to the [-1, 1] range using\n",
      "            the Transformer API (e.g. as part of a preprocessing\n",
      "            :class:`~sklearn.pipeline.Pipeline`).\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        NaNs are treated as missing values: disregarded to compute the statistics,\n",
      "        and maintained during the data transformation.\n",
      "\n",
      "        For a comparison of the different scalers, transformers, and normalizers,\n",
      "        see: :ref:`sphx_glr_auto_examples_preprocessing_plot_all_scaling.py`.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.preprocessing import maxabs_scale\n",
      "        >>> X = [[-2, 1, 2], [-1, 0, 1]]\n",
      "        >>> maxabs_scale(X, axis=0)  # scale each column independently\n",
      "        array([[-1. ,  1. ,  1. ],\n",
      "               [-0.5,  0. ,  0.5]])\n",
      "        >>> maxabs_scale(X, axis=1)  # scale each row independently\n",
      "        array([[-1. ,  0.5,  1. ],\n",
      "               [-1. ,  0. ,  1. ]])\n",
      "\n",
      "    minmax_scale(X, feature_range=(0, 1), *, axis=0, copy=True)\n",
      "        Transform features by scaling each feature to a given range.\n",
      "\n",
      "        This estimator scales and translates each feature individually such\n",
      "        that it is in the given range on the training set, i.e. between\n",
      "        zero and one.\n",
      "\n",
      "        The transformation is given by (when ``axis=0``)::\n",
      "\n",
      "            X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
      "            X_scaled = X_std * (max - min) + min\n",
      "\n",
      "        where min, max = feature_range.\n",
      "\n",
      "        The transformation is calculated as (when ``axis=0``)::\n",
      "\n",
      "           X_scaled = scale * X + min - X.min(axis=0) * scale\n",
      "           where scale = (max - min) / (X.max(axis=0) - X.min(axis=0))\n",
      "\n",
      "        This transformation is often used as an alternative to zero mean,\n",
      "        unit variance scaling.\n",
      "\n",
      "        Read more in the :ref:`User Guide <preprocessing_scaler>`.\n",
      "\n",
      "        .. versionadded:: 0.17\n",
      "           *minmax_scale* function interface\n",
      "           to :class:`~sklearn.preprocessing.MinMaxScaler`.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : array-like of shape (n_samples, n_features)\n",
      "            The data.\n",
      "\n",
      "        feature_range : tuple (min, max), default=(0, 1)\n",
      "            Desired range of transformed data.\n",
      "\n",
      "        axis : {0, 1}, default=0\n",
      "            Axis used to scale along. If 0, independently scale each feature,\n",
      "            otherwise (if 1) scale each sample.\n",
      "\n",
      "        copy : bool, default=True\n",
      "            If False, try to avoid a copy and scale in place.\n",
      "            This is not guaranteed to always work in place; e.g. if the data is\n",
      "            a numpy array with an int dtype, a copy will be returned even with\n",
      "            copy=False.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        X_tr : ndarray of shape (n_samples, n_features)\n",
      "            The transformed data.\n",
      "\n",
      "        .. warning:: Risk of data leak\n",
      "\n",
      "            Do not use :func:`~sklearn.preprocessing.minmax_scale` unless you know\n",
      "            what you are doing. A common mistake is to apply it to the entire data\n",
      "            *before* splitting into training and test sets. This will bias the\n",
      "            model evaluation because information would have leaked from the test\n",
      "            set to the training set.\n",
      "            In general, we recommend using\n",
      "            :class:`~sklearn.preprocessing.MinMaxScaler` within a\n",
      "            :ref:`Pipeline <pipeline>` in order to prevent most risks of data\n",
      "            leaking: `pipe = make_pipeline(MinMaxScaler(), LogisticRegression())`.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        MinMaxScaler : Performs scaling to a given range using the Transformer\n",
      "            API (e.g. as part of a preprocessing\n",
      "            :class:`~sklearn.pipeline.Pipeline`).\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        For a comparison of the different scalers, transformers, and normalizers,\n",
      "        see: :ref:`sphx_glr_auto_examples_preprocessing_plot_all_scaling.py`.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.preprocessing import minmax_scale\n",
      "        >>> X = [[-2, 1, 2], [-1, 0, 1]]\n",
      "        >>> minmax_scale(X, axis=0)  # scale each column independently\n",
      "        array([[0., 1., 1.],\n",
      "               [1., 0., 0.]])\n",
      "        >>> minmax_scale(X, axis=1)  # scale each row independently\n",
      "        array([[0.  , 0.75, 1.  ],\n",
      "               [0.  , 0.5 , 1.  ]])\n",
      "\n",
      "    normalize(X, norm='l2', *, axis=1, copy=True, return_norm=False)\n",
      "        Scale input vectors individually to unit norm (vector length).\n",
      "\n",
      "        Read more in the :ref:`User Guide <preprocessing_normalization>`.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The data to normalize, element by element.\n",
      "            scipy.sparse matrices should be in CSR format to avoid an\n",
      "            un-necessary copy.\n",
      "\n",
      "        norm : {'l1', 'l2', 'max'}, default='l2'\n",
      "            The norm to use to normalize each non zero sample (or each non-zero\n",
      "            feature if axis is 0).\n",
      "\n",
      "        axis : {0, 1}, default=1\n",
      "            Define axis used to normalize the data along. If 1, independently\n",
      "            normalize each sample, otherwise (if 0) normalize each feature.\n",
      "\n",
      "        copy : bool, default=True\n",
      "            If False, try to avoid a copy and normalize in place.\n",
      "            This is not guaranteed to always work in place; e.g. if the data is\n",
      "            a numpy array with an int dtype, a copy will be returned even with\n",
      "            copy=False.\n",
      "\n",
      "        return_norm : bool, default=False\n",
      "            Whether to return the computed norms.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        X : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      "            Normalized input X.\n",
      "\n",
      "        norms : ndarray of shape (n_samples, ) if axis=1 else (n_features, )\n",
      "            An array of norms along given axis for X.\n",
      "            When X is sparse, a NotImplementedError will be raised\n",
      "            for norm 'l1' or 'l2'.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        Normalizer : Performs normalization using the Transformer API\n",
      "            (e.g. as part of a preprocessing :class:`~sklearn.pipeline.Pipeline`).\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        For a comparison of the different scalers, transformers, and normalizers,\n",
      "        see: :ref:`sphx_glr_auto_examples_preprocessing_plot_all_scaling.py`.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.preprocessing import normalize\n",
      "        >>> X = [[-2, 1, 2], [-1, 0, 1]]\n",
      "        >>> normalize(X, norm=\"l1\")  # L1 normalization each row independently\n",
      "        array([[-0.4,  0.2,  0.4],\n",
      "               [-0.5,  0. ,  0.5]])\n",
      "        >>> normalize(X, norm=\"l2\")  # L2 normalization each row independently\n",
      "        array([[-0.66...,  0.33...,  0.66...],\n",
      "               [-0.70...,  0.     ,  0.70...]])\n",
      "\n",
      "    power_transform(X, method='yeo-johnson', *, standardize=True, copy=True)\n",
      "        Parametric, monotonic transformation to make data more Gaussian-like.\n",
      "\n",
      "        Power transforms are a family of parametric, monotonic transformations\n",
      "        that are applied to make data more Gaussian-like. This is useful for\n",
      "        modeling issues related to heteroscedasticity (non-constant variance),\n",
      "        or other situations where normality is desired.\n",
      "\n",
      "        Currently, power_transform supports the Box-Cox transform and the\n",
      "        Yeo-Johnson transform. The optimal parameter for stabilizing variance and\n",
      "        minimizing skewness is estimated through maximum likelihood.\n",
      "\n",
      "        Box-Cox requires input data to be strictly positive, while Yeo-Johnson\n",
      "        supports both positive or negative data.\n",
      "\n",
      "        By default, zero-mean, unit-variance normalization is applied to the\n",
      "        transformed data.\n",
      "\n",
      "        Read more in the :ref:`User Guide <preprocessing_transformer>`.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : array-like of shape (n_samples, n_features)\n",
      "            The data to be transformed using a power transformation.\n",
      "\n",
      "        method : {'yeo-johnson', 'box-cox'}, default='yeo-johnson'\n",
      "            The power transform method. Available methods are:\n",
      "\n",
      "            - 'yeo-johnson' [1]_, works with positive and negative values\n",
      "            - 'box-cox' [2]_, only works with strictly positive values\n",
      "\n",
      "            .. versionchanged:: 0.23\n",
      "                The default value of the `method` parameter changed from\n",
      "                'box-cox' to 'yeo-johnson' in 0.23.\n",
      "\n",
      "        standardize : bool, default=True\n",
      "            Set to True to apply zero-mean, unit-variance normalization to the\n",
      "            transformed output.\n",
      "\n",
      "        copy : bool, default=True\n",
      "            If False, try to avoid a copy and transform in place.\n",
      "            This is not guaranteed to always work in place; e.g. if the data is\n",
      "            a numpy array with an int dtype, a copy will be returned even with\n",
      "            copy=False.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        X_trans : ndarray of shape (n_samples, n_features)\n",
      "            The transformed data.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        PowerTransformer : Equivalent transformation with the\n",
      "            Transformer API (e.g. as part of a preprocessing\n",
      "            :class:`~sklearn.pipeline.Pipeline`).\n",
      "\n",
      "        quantile_transform : Maps data to a standard normal distribution with\n",
      "            the parameter `output_distribution='normal'`.\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        NaNs are treated as missing values: disregarded in ``fit``, and maintained\n",
      "        in ``transform``.\n",
      "\n",
      "        For a comparison of the different scalers, transformers, and normalizers,\n",
      "        see: :ref:`sphx_glr_auto_examples_preprocessing_plot_all_scaling.py`.\n",
      "\n",
      "        References\n",
      "        ----------\n",
      "\n",
      "        .. [1] I.K. Yeo and R.A. Johnson, \"A new family of power transformations to\n",
      "               improve normality or symmetry.\" Biometrika, 87(4), pp.954-959,\n",
      "               (2000).\n",
      "\n",
      "        .. [2] G.E.P. Box and D.R. Cox, \"An Analysis of Transformations\", Journal\n",
      "               of the Royal Statistical Society B, 26, 211-252 (1964).\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> import numpy as np\n",
      "        >>> from sklearn.preprocessing import power_transform\n",
      "        >>> data = [[1, 2], [3, 2], [4, 5]]\n",
      "        >>> print(power_transform(data, method='box-cox'))\n",
      "        [[-1.332... -0.707...]\n",
      "         [ 0.256... -0.707...]\n",
      "         [ 1.076...  1.414...]]\n",
      "\n",
      "        .. warning:: Risk of data leak.\n",
      "            Do not use :func:`~sklearn.preprocessing.power_transform` unless you\n",
      "            know what you are doing. A common mistake is to apply it to the entire\n",
      "            data *before* splitting into training and test sets. This will bias the\n",
      "            model evaluation because information would have leaked from the test\n",
      "            set to the training set.\n",
      "            In general, we recommend using\n",
      "            :class:`~sklearn.preprocessing.PowerTransformer` within a\n",
      "            :ref:`Pipeline <pipeline>` in order to prevent most risks of data\n",
      "            leaking, e.g.: `pipe = make_pipeline(PowerTransformer(),\n",
      "            LogisticRegression())`.\n",
      "\n",
      "    quantile_transform(X, *, axis=0, n_quantiles=1000, output_distribution='uniform', ignore_implicit_zeros=False, subsample=100000, random_state=None, copy=True)\n",
      "        Transform features using quantiles information.\n",
      "\n",
      "        This method transforms the features to follow a uniform or a normal\n",
      "        distribution. Therefore, for a given feature, this transformation tends\n",
      "        to spread out the most frequent values. It also reduces the impact of\n",
      "        (marginal) outliers: this is therefore a robust preprocessing scheme.\n",
      "\n",
      "        The transformation is applied on each feature independently. First an\n",
      "        estimate of the cumulative distribution function of a feature is\n",
      "        used to map the original values to a uniform distribution. The obtained\n",
      "        values are then mapped to the desired output distribution using the\n",
      "        associated quantile function. Features values of new/unseen data that fall\n",
      "        below or above the fitted range will be mapped to the bounds of the output\n",
      "        distribution. Note that this transform is non-linear. It may distort linear\n",
      "        correlations between variables measured at the same scale but renders\n",
      "        variables measured at different scales more directly comparable.\n",
      "\n",
      "        Read more in the :ref:`User Guide <preprocessing_transformer>`.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The data to transform.\n",
      "\n",
      "        axis : int, default=0\n",
      "            Axis used to compute the means and standard deviations along. If 0,\n",
      "            transform each feature, otherwise (if 1) transform each sample.\n",
      "\n",
      "        n_quantiles : int, default=1000 or n_samples\n",
      "            Number of quantiles to be computed. It corresponds to the number\n",
      "            of landmarks used to discretize the cumulative distribution function.\n",
      "            If n_quantiles is larger than the number of samples, n_quantiles is set\n",
      "            to the number of samples as a larger number of quantiles does not give\n",
      "            a better approximation of the cumulative distribution function\n",
      "            estimator.\n",
      "\n",
      "        output_distribution : {'uniform', 'normal'}, default='uniform'\n",
      "            Marginal distribution for the transformed data. The choices are\n",
      "            'uniform' (default) or 'normal'.\n",
      "\n",
      "        ignore_implicit_zeros : bool, default=False\n",
      "            Only applies to sparse matrices. If True, the sparse entries of the\n",
      "            matrix are discarded to compute the quantile statistics. If False,\n",
      "            these entries are treated as zeros.\n",
      "\n",
      "        subsample : int or None, default=1e5\n",
      "            Maximum number of samples used to estimate the quantiles for\n",
      "            computational efficiency. Note that the subsampling procedure may\n",
      "            differ for value-identical sparse and dense matrices.\n",
      "            Disable subsampling by setting `subsample=None`.\n",
      "\n",
      "            .. versionadded:: 1.5\n",
      "               The option `None` to disable subsampling was added.\n",
      "\n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for subsampling and smoothing\n",
      "            noise.\n",
      "            Please see ``subsample`` for more details.\n",
      "            Pass an int for reproducible results across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "\n",
      "        copy : bool, default=True\n",
      "            If False, try to avoid a copy and transform in place.\n",
      "            This is not guaranteed to always work in place; e.g. if the data is\n",
      "            a numpy array with an int dtype, a copy will be returned even with\n",
      "            copy=False.\n",
      "\n",
      "            .. versionchanged:: 0.23\n",
      "                The default value of `copy` changed from False to True in 0.23.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        Xt : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      "            The transformed data.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        QuantileTransformer : Performs quantile-based scaling using the\n",
      "            Transformer API (e.g. as part of a preprocessing\n",
      "            :class:`~sklearn.pipeline.Pipeline`).\n",
      "        power_transform : Maps data to a normal distribution using a\n",
      "            power transformation.\n",
      "        scale : Performs standardization that is faster, but less robust\n",
      "            to outliers.\n",
      "        robust_scale : Performs robust standardization that removes the influence\n",
      "            of outliers but does not put outliers and inliers on the same scale.\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        NaNs are treated as missing values: disregarded in fit, and maintained in\n",
      "        transform.\n",
      "\n",
      "        .. warning:: Risk of data leak\n",
      "\n",
      "            Do not use :func:`~sklearn.preprocessing.quantile_transform` unless\n",
      "            you know what you are doing. A common mistake is to apply it\n",
      "            to the entire data *before* splitting into training and\n",
      "            test sets. This will bias the model evaluation because\n",
      "            information would have leaked from the test set to the\n",
      "            training set.\n",
      "            In general, we recommend using\n",
      "            :class:`~sklearn.preprocessing.QuantileTransformer` within a\n",
      "            :ref:`Pipeline <pipeline>` in order to prevent most risks of data\n",
      "            leaking:`pipe = make_pipeline(QuantileTransformer(),\n",
      "            LogisticRegression())`.\n",
      "\n",
      "        For a comparison of the different scalers, transformers, and normalizers,\n",
      "        see: :ref:`sphx_glr_auto_examples_preprocessing_plot_all_scaling.py`.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> import numpy as np\n",
      "        >>> from sklearn.preprocessing import quantile_transform\n",
      "        >>> rng = np.random.RandomState(0)\n",
      "        >>> X = np.sort(rng.normal(loc=0.5, scale=0.25, size=(25, 1)), axis=0)\n",
      "        >>> quantile_transform(X, n_quantiles=10, random_state=0, copy=True)\n",
      "        array([...])\n",
      "\n",
      "    robust_scale(X, *, axis=0, with_centering=True, with_scaling=True, quantile_range=(25.0, 75.0), copy=True, unit_variance=False)\n",
      "        Standardize a dataset along any axis.\n",
      "\n",
      "        Center to the median and component wise scale\n",
      "        according to the interquartile range.\n",
      "\n",
      "        Read more in the :ref:`User Guide <preprocessing_scaler>`.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_sample, n_features)\n",
      "            The data to center and scale.\n",
      "\n",
      "        axis : int, default=0\n",
      "            Axis used to compute the medians and IQR along. If 0,\n",
      "            independently scale each feature, otherwise (if 1) scale\n",
      "            each sample.\n",
      "\n",
      "        with_centering : bool, default=True\n",
      "            If `True`, center the data before scaling.\n",
      "\n",
      "        with_scaling : bool, default=True\n",
      "            If `True`, scale the data to unit variance (or equivalently,\n",
      "            unit standard deviation).\n",
      "\n",
      "        quantile_range : tuple (q_min, q_max), 0.0 < q_min < q_max < 100.0,        default=(25.0, 75.0)\n",
      "            Quantile range used to calculate `scale_`. By default this is equal to\n",
      "            the IQR, i.e., `q_min` is the first quantile and `q_max` is the third\n",
      "            quantile.\n",
      "\n",
      "            .. versionadded:: 0.18\n",
      "\n",
      "        copy : bool, default=True\n",
      "            If False, try to avoid a copy and scale in place.\n",
      "            This is not guaranteed to always work in place; e.g. if the data is\n",
      "            a numpy array with an int dtype, a copy will be returned even with\n",
      "            copy=False.\n",
      "\n",
      "        unit_variance : bool, default=False\n",
      "            If `True`, scale data so that normally distributed features have a\n",
      "            variance of 1. In general, if the difference between the x-values of\n",
      "            `q_max` and `q_min` for a standard normal distribution is greater\n",
      "            than 1, the dataset will be scaled down. If less than 1, the dataset\n",
      "            will be scaled up.\n",
      "\n",
      "            .. versionadded:: 0.24\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      "            The transformed data.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        RobustScaler : Performs centering and scaling using the Transformer API\n",
      "            (e.g. as part of a preprocessing :class:`~sklearn.pipeline.Pipeline`).\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        This implementation will refuse to center scipy.sparse matrices\n",
      "        since it would make them non-sparse and would potentially crash the\n",
      "        program with memory exhaustion problems.\n",
      "\n",
      "        Instead the caller is expected to either set explicitly\n",
      "        `with_centering=False` (in that case, only variance scaling will be\n",
      "        performed on the features of the CSR matrix) or to call `X.toarray()`\n",
      "        if he/she expects the materialized dense array to fit in memory.\n",
      "\n",
      "        To avoid memory copy the caller should pass a CSR matrix.\n",
      "\n",
      "        For a comparison of the different scalers, transformers, and normalizers,\n",
      "        see: :ref:`sphx_glr_auto_examples_preprocessing_plot_all_scaling.py`.\n",
      "\n",
      "        .. warning:: Risk of data leak\n",
      "\n",
      "            Do not use :func:`~sklearn.preprocessing.robust_scale` unless you know\n",
      "            what you are doing. A common mistake is to apply it to the entire data\n",
      "            *before* splitting into training and test sets. This will bias the\n",
      "            model evaluation because information would have leaked from the test\n",
      "            set to the training set.\n",
      "            In general, we recommend using\n",
      "            :class:`~sklearn.preprocessing.RobustScaler` within a\n",
      "            :ref:`Pipeline <pipeline>` in order to prevent most risks of data\n",
      "            leaking: `pipe = make_pipeline(RobustScaler(), LogisticRegression())`.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.preprocessing import robust_scale\n",
      "        >>> X = [[-2, 1, 2], [-1, 0, 1]]\n",
      "        >>> robust_scale(X, axis=0)  # scale each column independently\n",
      "        array([[-1.,  1.,  1.],\n",
      "               [ 1., -1., -1.]])\n",
      "        >>> robust_scale(X, axis=1)  # scale each row independently\n",
      "        array([[-1.5,  0. ,  0.5],\n",
      "               [-1. ,  0. ,  1. ]])\n",
      "\n",
      "    scale(X, *, axis=0, with_mean=True, with_std=True, copy=True)\n",
      "        Standardize a dataset along any axis.\n",
      "\n",
      "        Center to the mean and component wise scale to unit variance.\n",
      "\n",
      "        Read more in the :ref:`User Guide <preprocessing_scaler>`.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The data to center and scale.\n",
      "\n",
      "        axis : {0, 1}, default=0\n",
      "            Axis used to compute the means and standard deviations along. If 0,\n",
      "            independently standardize each feature, otherwise (if 1) standardize\n",
      "            each sample.\n",
      "\n",
      "        with_mean : bool, default=True\n",
      "            If True, center the data before scaling.\n",
      "\n",
      "        with_std : bool, default=True\n",
      "            If True, scale the data to unit variance (or equivalently,\n",
      "            unit standard deviation).\n",
      "\n",
      "        copy : bool, default=True\n",
      "            If False, try to avoid a copy and scale in place.\n",
      "            This is not guaranteed to always work in place; e.g. if the data is\n",
      "            a numpy array with an int dtype, a copy will be returned even with\n",
      "            copy=False.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)\n",
      "            The transformed data.\n",
      "\n",
      "        See Also\n",
      "        --------\n",
      "        StandardScaler : Performs scaling to unit variance using the Transformer\n",
      "            API (e.g. as part of a preprocessing\n",
      "            :class:`~sklearn.pipeline.Pipeline`).\n",
      "\n",
      "        Notes\n",
      "        -----\n",
      "        This implementation will refuse to center scipy.sparse matrices\n",
      "        since it would make them non-sparse and would potentially crash the\n",
      "        program with memory exhaustion problems.\n",
      "\n",
      "        Instead the caller is expected to either set explicitly\n",
      "        `with_mean=False` (in that case, only variance scaling will be\n",
      "        performed on the features of the CSC matrix) or to call `X.toarray()`\n",
      "        if he/she expects the materialized dense array to fit in memory.\n",
      "\n",
      "        To avoid memory copy the caller should pass a CSC matrix.\n",
      "\n",
      "        NaNs are treated as missing values: disregarded to compute the statistics,\n",
      "        and maintained during the data transformation.\n",
      "\n",
      "        We use a biased estimator for the standard deviation, equivalent to\n",
      "        `numpy.std(x, ddof=0)`. Note that the choice of `ddof` is unlikely to\n",
      "        affect model performance.\n",
      "\n",
      "        For a comparison of the different scalers, transformers, and normalizers,\n",
      "        see: :ref:`sphx_glr_auto_examples_preprocessing_plot_all_scaling.py`.\n",
      "\n",
      "        .. warning:: Risk of data leak\n",
      "\n",
      "            Do not use :func:`~sklearn.preprocessing.scale` unless you know\n",
      "            what you are doing. A common mistake is to apply it to the entire data\n",
      "            *before* splitting into training and test sets. This will bias the\n",
      "            model evaluation because information would have leaked from the test\n",
      "            set to the training set.\n",
      "            In general, we recommend using\n",
      "            :class:`~sklearn.preprocessing.StandardScaler` within a\n",
      "            :ref:`Pipeline <pipeline>` in order to prevent most risks of data\n",
      "            leaking: `pipe = make_pipeline(StandardScaler(), LogisticRegression())`.\n",
      "\n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.preprocessing import scale\n",
      "        >>> X = [[-2, 1, 2], [-1, 0, 1]]\n",
      "        >>> scale(X, axis=0)  # scaling each column independently\n",
      "        array([[-1.,  1.,  1.],\n",
      "               [ 1., -1., -1.]])\n",
      "        >>> scale(X, axis=1)  # scaling each row independently\n",
      "        array([[-1.37...,  0.39...,  0.98...],\n",
      "               [-1.22...,  0.     ,  1.22...]])\n",
      "\n",
      "DATA\n",
      "    __all__ = ['Binarizer', 'FunctionTransformer', 'KBinsDiscretizer', 'Ke...\n",
      "\n",
      "FILE\n",
      "    c:\\users\\timon\\appdata\\roaming\\python\\python312\\site-packages\\sklearn\\preprocessing\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "help(sklearn.preprocessing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
